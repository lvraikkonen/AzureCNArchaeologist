#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HTMLå¤„ç†å·¥å…·æ¨¡å—
"""

import json
import os
from typing import Dict, List, Set, Optional, Tuple
from bs4 import BeautifulSoup, Comment, NavigableString
from datetime import datetime


class RegionFilterProcessor:
    """åŒºåŸŸè¡¨æ ¼è¿‡æ»¤å¤„ç†å™¨"""
    
    def __init__(self, config_file_path: str = "soft-category.json"):
        """
        åˆå§‹åŒ–è¿‡æ»¤å™¨
        
        Args:
            config_file_path: åŒºåŸŸé…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_file_path = config_file_path
        self.region_filter_config = {}
        self.active_region = None
        self.load_region_filter_config()
    
    def load_region_filter_config(self) -> bool:
        """åŠ è½½åŒºåŸŸè¿‡æ»¤é…ç½®"""
        try:
            if not os.path.exists(self.config_file_path):
                print(f"âš  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_file_path}")
                return False
                
            with open(self.config_file_path, 'r', encoding='utf-8') as f:
                config_data = json.load(f)
            
            # æ„å»ºä»¥äº§å“å’ŒåŒºåŸŸä¸ºé”®çš„é…ç½®å­—å…¸
            for item in config_data:
                os_name = item.get('os', '')
                region = item.get('region', '')
                table_ids = item.get('tableIDs', [])
                
                if region:
                    # ä¸ºæ¯ä¸ªäº§å“åˆ›å»ºç‹¬ç«‹çš„é…ç½®ç©ºé—´
                    if os_name not in self.region_filter_config:
                        self.region_filter_config[os_name] = {}
                    self.region_filter_config[os_name][region] = table_ids
            
            print(f"âœ“ å·²åŠ è½½åŒºåŸŸè¿‡æ»¤é…ç½®: {len(config_data)}æ¡è§„åˆ™")
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def set_active_region(self, region: str, product: str = "Azure Database for MySQL"):
        """
        è®¾ç½®å½“å‰æ´»è·ƒåŒºåŸŸ
        
        Args:
            region: åŒºåŸŸID
            product: äº§å“åç§°
        """
        self.active_region = region
        self.active_product = product
        print(f"âœ“ è®¾ç½®æ´»è·ƒåŒºåŸŸ: {region} (äº§å“: {product})")
    
    def should_filter_table(self, table_id: str) -> bool:
        """
        åˆ¤æ–­è¡¨æ ¼æ˜¯å¦åº”è¯¥è¢«è¿‡æ»¤ (æ”¹è¿›ç‰ˆ)
        
        Args:
            table_id: è¡¨æ ¼ID
            
        Returns:
            bool: True=è¿‡æ»¤ï¼ˆéšè—ï¼‰ï¼ŒFalse=ä¿ç•™æ˜¾ç¤º
        """
        try:
            # åŸºç¡€éªŒè¯
            if not table_id or not isinstance(table_id, str):
                return False
                
            if not self.active_region or not hasattr(self, 'active_product'):
                return False

            # è·å–å½“å‰äº§å“å’ŒåŒºåŸŸçš„é…ç½®
            product_config = self.region_filter_config.get(self.active_product, {})
            excluded_tables = product_config.get(self.active_region)
            
            # è§„åˆ™1: åŒºåŸŸä¸åœ¨é…ç½®ä¸­ â†’ ä¸è¿‡æ»¤
            if excluded_tables is None:
                return False

            # è§„åˆ™2: æ’é™¤åˆ—è¡¨ä¸ºç©º â†’ ä¸è¿‡æ»¤
            if not excluded_tables:
                return False

            # è§„åˆ™3: æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­ (æ”¯æŒå¤šç§æ ¼å¼åŒ¹é…)
            table_id_clean = table_id.strip()
            table_id_with_hash = f"#{table_id_clean}" if not table_id_clean.startswith('#') else table_id_clean
            table_id_without_hash = table_id_clean[1:] if table_id_clean.startswith('#') and len(table_id_clean) > 1 else table_id_clean

            is_excluded = (table_id_clean in excluded_tables or
                          table_id_with_hash in excluded_tables or
                          table_id_without_hash in excluded_tables)
            
            return is_excluded
                
        except Exception as e:
            print(f"âš  è¡¨æ ¼è¿‡æ»¤åˆ¤æ–­å¼‚å¸¸ (table_id: {table_id}): {e}")
            # å¼‚å¸¸æ—¶ä¿å®ˆå¤„ç†ï¼šä¸è¿‡æ»¤ï¼ˆæ˜¾ç¤ºè¡¨æ ¼ï¼‰
            return False
    
    def get_excluded_tables_for_region(self, region: str, product: str = "Azure Database for MySQL") -> List[str]:
        """è·å–æŒ‡å®šåŒºåŸŸçš„æ’é™¤è¡¨æ ¼åˆ—è¡¨"""
        product_config = self.region_filter_config.get(product, {})
        return product_config.get(region, [])
    
    def get_available_regions(self, product: str = "Azure Database for MySQL") -> List[str]:
        """è·å–äº§å“å¯ç”¨åŒºåŸŸåˆ—è¡¨"""
        product_config = self.region_filter_config.get(product, {})
        return list(product_config.keys())


class HTMLProcessor:
    """HTMLå¤„ç†å™¨"""
    
    def __init__(self, region_filter: Optional[RegionFilterProcessor] = None):
        """
        åˆå§‹åŒ–HTMLå¤„ç†å™¨
        
        Args:
            region_filter: åŒºåŸŸè¿‡æ»¤å¤„ç†å™¨å®ä¾‹
        """
        self.region_filter = region_filter or RegionFilterProcessor()
        self.removed_elements_log = []  # è®°å½•ç§»é™¤çš„å…ƒç´ æ—¥å¿—
    
    def remove_unwanted_elements(self, soup: BeautifulSoup) -> int:
        """
        ç§»é™¤ä¸éœ€è¦çš„HTMLå…ƒç´ 
        
        Args:
            soup: BeautifulSoupå¯¹è±¡
            
        Returns:
            int: ç§»é™¤çš„å…ƒç´ æ•°é‡
        """
        removed_count = 0
        
        # 1. ç§»é™¤æ ·å¼å’Œè„šæœ¬æ ‡ç­¾
        print("  ğŸ—‘ï¸ ç§»é™¤æ ·å¼å’Œè„šæœ¬æ ‡ç­¾...")
        for tag in soup.find_all(['link', 'style', 'script']):
            tag.decompose()
            removed_count += 1
        
        # 2. ç§»é™¤HTMLæ³¨é‡Š
        print("  ğŸ—‘ï¸ ç§»é™¤HTMLæ³¨é‡Š...")
        for comment in soup.find_all(string=lambda text: isinstance(text, Comment)):
            comment.extract()
            removed_count += 1
        
        # 3. ç§»é™¤äº¤äº’å¼UIå…ƒç´ 
        print("  ğŸ—‘ï¸ ç§»é™¤äº¤äº’å¼UIå…ƒç´ ...")
        interactive_selectors = [
            ('div', 'region-container'),
            ('div', 'software-kind-container'), 
            ('ul', 'tab-nav'),
            ('div', 'documentation-navigation'),
            ('div', 'acn-header-container'),
            ('div', 'public_footerpage'),
            ('div', 'left-navigation-select'),
            ('div', 'bread-crumb'),
            ('div', 'loader'),  # åŠ è½½åŠ¨ç”»
            ('select', None)  # æ‰€æœ‰selectå…ƒç´ 
        ]
        
        for tag_name, class_name in interactive_selectors:
            if class_name:
                elements = soup.find_all(tag_name, class_=class_name)
            else:
                elements = soup.find_all(tag_name)
                
            for element in elements:
                element.decompose()
                removed_count += 1
        
        # 4. ğŸ†• å±•å¼€tabå®¹å™¨ï¼Œä¿ç•™å†…éƒ¨å†…å®¹
        print("  ğŸ“‚ å±•å¼€tabå®¹å™¨...")
        tab_containers_processed = self._flatten_tab_containers(soup)
        removed_count += tab_containers_processed
        
        # 5. ğŸ†• ç§»é™¤ç©ºçš„å®¹å™¨å…ƒç´ 
        print("  ğŸ§¹ æ¸…ç†ç©ºå®¹å™¨...")
        empty_containers_removed = self._remove_empty_containers(soup)
        removed_count += empty_containers_removed
        
        return removed_count
    
    def _flatten_tab_containers(self, soup: BeautifulSoup) -> int:
        """
        å±•å¼€tabå®¹å™¨ï¼Œåªä¿ç•™å†…éƒ¨çš„å…·ä½“å†…å®¹
        
        Args:
            soup: BeautifulSoupå¯¹è±¡
            
        Returns:
            int: å¤„ç†çš„å®¹å™¨æ•°é‡
        """
        processed_count = 0
        
        # å¤„ç†tab-contentå®¹å™¨
        tab_contents = soup.find_all('div', class_='tab-content')
        for tab_content in tab_contents:
            print(f"    ğŸ“‚ å¤„ç†tab-contentå®¹å™¨...")
            
            # æ”¶é›†æ‰€æœ‰tab-panelä¸­çš„å†…å®¹
            all_content = []
            tab_panels = tab_content.find_all('div', class_='tab-panel')
            
            for panel in tab_panels:
                panel_id = panel.get('id', '')
                print(f"      ğŸ“„ æå–panelå†…å®¹: {panel_id}")
                
                # æå–panelä¸­çš„æ‰€æœ‰å†…å®¹ï¼ˆé™¤äº†åµŒå¥—çš„tabç»“æ„ï¼‰
                content_elements = self._extract_panel_content(panel)
                all_content.extend(content_elements)
            
            # ç”¨æå–çš„å†…å®¹æ›¿æ¢æ•´ä¸ªtab-content
            if all_content:
                # åœ¨tab-contentä½ç½®æ’å…¥æ‰€æœ‰å†…å®¹
                for element in all_content:
                    tab_content.insert_before(element)
                
                # ç§»é™¤åŸå§‹çš„tab-contentå®¹å™¨
                tab_content.decompose()
                processed_count += 1
        
        # å¤„ç†å…¶ä»–tabç›¸å…³å®¹å™¨
        tab_related_classes = [
            'tab-container',
            'tab-container-container', 
            'tab-container-box',
            'technical-azure-selector',
            'pricing-detail-tab'
        ]
        
        for class_name in tab_related_classes:
            containers = soup.find_all('div', class_=class_name)
            for container in containers:
                print(f"    ğŸ“‚ å¤„ç†{class_name}å®¹å™¨...")
                
                # æå–å®¹å™¨ä¸­çš„æœ‰ç”¨å†…å®¹
                useful_content = self._extract_useful_content(container)
                
                if useful_content:
                    # åœ¨å®¹å™¨ä½ç½®æ’å…¥æœ‰ç”¨å†…å®¹
                    for element in useful_content:
                        container.insert_before(element)
                
                # ç§»é™¤åŸå§‹å®¹å™¨
                container.decompose()
                processed_count += 1
        
        return processed_count
    
    def _extract_panel_content(self, panel) -> List:
        """
        ä»tab panelä¸­æå–æœ‰ç”¨å†…å®¹
        
        Args:
            panel: tab panelå…ƒç´ 
            
        Returns:
            List: æå–çš„å†…å®¹å…ƒç´ åˆ—è¡¨
        """
        extracted_content = []
        
        # è¦ä¿ç•™çš„å†…å®¹ç±»å‹
        content_tags = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p', 'table', 'ul', 'ol', 'div']
        
        for child in panel.find_all(content_tags, recursive=False):
            # è·³è¿‡åµŒå¥—çš„tabç»“æ„
            if self._is_tab_related_element(child):
                continue
                
            # å¤åˆ¶å…ƒç´ ï¼ˆé¿å…ç§»åŠ¨æ—¶ç ´ååŸå§‹ç»“æ„ï¼‰
            cloned_element = BeautifulSoup(str(child), 'html.parser').find()
            if cloned_element:
                extracted_content.append(cloned_element)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›´æ¥å­å…ƒç´ ï¼Œå°è¯•æå–æ‰€æœ‰étabç›¸å…³å†…å®¹
        if not extracted_content:
            for element in panel.find_all(content_tags):
                if not self._is_tab_related_element(element):
                    cloned_element = BeautifulSoup(str(element), 'html.parser').find()
                    if cloned_element:
                        extracted_content.append(cloned_element)
        
        return extracted_content
    
    def _extract_useful_content(self, container) -> List:
        """
        ä»å®¹å™¨ä¸­æå–æœ‰ç”¨å†…å®¹
        
        Args:
            container: å®¹å™¨å…ƒç´ 
            
        Returns:
            List: æå–çš„å†…å®¹å…ƒç´ åˆ—è¡¨
        """
        extracted_content = []
        
        # ç›´æ¥æŸ¥æ‰¾æœ‰ç”¨çš„å†…å®¹å…ƒç´ 
        useful_tags = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p', 'table', 'ul', 'ol']
        
        for tag in useful_tags:
            elements = container.find_all(tag)
            for element in elements:
                # ç¡®ä¿ä¸æ˜¯tabç›¸å…³çš„å…ƒç´ 
                if not self._is_tab_related_element(element):
                    cloned_element = BeautifulSoup(str(element), 'html.parser').find()
                    if cloned_element:
                        extracted_content.append(cloned_element)
        
        return extracted_content
    
    def _is_tab_related_element(self, element) -> bool:
        """
        åˆ¤æ–­å…ƒç´ æ˜¯å¦æ˜¯tabç›¸å…³çš„
        
        Args:
            element: è¦æ£€æŸ¥çš„å…ƒç´ 
            
        Returns:
            bool: æ˜¯å¦æ˜¯tabç›¸å…³å…ƒç´ 
        """
        if not element or not hasattr(element, 'get'):
            return False
            
        # æ£€æŸ¥classå±æ€§
        classes = element.get('class', [])
        if isinstance(classes, str):
            classes = [classes]
            
        tab_related_classes = [
            'tab-nav', 'tab-content', 'tab-panel', 'tab-container',
            'dropdown-container', 'dropdown-box', 'tab-items'
        ]
        
        return any(tab_class in ' '.join(classes) for tab_class in tab_related_classes)
    
    def _remove_empty_containers(self, soup: BeautifulSoup) -> int:
        """
        ç§»é™¤ç©ºçš„å®¹å™¨å…ƒç´ 
        
        Args:
            soup: BeautifulSoupå¯¹è±¡
            
        Returns:
            int: ç§»é™¤çš„ç©ºå®¹å™¨æ•°é‡
        """
        removed_count = 0
        
        # è¦æ£€æŸ¥çš„å®¹å™¨æ ‡ç­¾
        container_tags = ['div', 'section', 'article', 'aside']
        
        # å¤šæ¬¡æ¸…ç†ï¼Œå› ä¸ºç§»é™¤åµŒå¥—çš„ç©ºå®¹å™¨å¯èƒ½éœ€è¦å¤šè½®
        max_iterations = 3
        for iteration in range(max_iterations):
            containers_removed_this_round = 0
            
            for tag_name in container_tags:
                containers = soup.find_all(tag_name)
                for container in containers:
                    if self._is_empty_container(container):
                        container.decompose()
                        containers_removed_this_round += 1
                        removed_count += 1
            
            # å¦‚æœè¿™è½®æ²¡æœ‰ç§»é™¤ä»»ä½•å®¹å™¨ï¼Œåœæ­¢è¿­ä»£
            if containers_removed_this_round == 0:
                break
        
        if removed_count > 0:
            print(f"    ğŸ—‘ï¸ ç§»é™¤äº†{removed_count}ä¸ªç©ºå®¹å™¨")
        
        return removed_count
    
    def _is_empty_container(self, container) -> bool:
        """
        åˆ¤æ–­å®¹å™¨æ˜¯å¦ä¸ºç©º
        
        Args:
            container: è¦æ£€æŸ¥çš„å®¹å™¨å…ƒç´ 
            
        Returns:
            bool: æ˜¯å¦ä¸ºç©ºå®¹å™¨
        """
        if not container:
            return True
        
        # è·å–å®¹å™¨çš„æ–‡æœ¬å†…å®¹ï¼ˆå»é™¤ç©ºç™½ï¼‰
        text_content = container.get_text(strip=True)
        
        # å¦‚æœæœ‰æ–‡æœ¬å†…å®¹ï¼Œä¸æ˜¯ç©ºå®¹å™¨
        if text_content:
            return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«é‡è¦çš„éæ–‡æœ¬å…ƒç´ 
        important_tags = ['table', 'img', 'input', 'button', 'iframe', 'video', 'audio']
        if container.find_all(important_tags):
            return False
        
        # å¦‚æœåªåŒ…å«å…¶ä»–ç©ºå®¹å™¨ï¼Œä¹Ÿè®¤ä¸ºæ˜¯ç©ºçš„
        return True
    
    def filter_tables_by_region(self, soup: BeautifulSoup, region: str, product: str = "Azure Database for MySQL") -> Tuple[int, int, List[str]]:
        """
        æŒ‰åŒºåŸŸè¿‡æ»¤è¡¨æ ¼
        
        Args:
            soup: BeautifulSoupå¯¹è±¡
            region: ç›®æ ‡åŒºåŸŸ
            product: äº§å“åç§°
            
        Returns:
            Tuple[int, int, List[str]]: (è¿‡æ»¤æ•°é‡, ä¿ç•™æ•°é‡, ä¿ç•™çš„è¡¨æ ¼IDåˆ—è¡¨)
        """
        if not self.region_filter:
            return 0, 0, []
        
        # è®¾ç½®æ´»è·ƒåŒºåŸŸ
        self.region_filter.set_active_region(region, product)
        
        filtered_count = 0
        retained_count = 0
        retained_table_ids = []
        
        all_tables = soup.find_all('table')
        total_tables = len(all_tables)
        
        print(f"ğŸ“Š å¼€å§‹è¡¨æ ¼è¿‡æ»¤: æ€»è®¡{total_tables}ä¸ªè¡¨æ ¼")
        
        for table in all_tables:
            table_id = table.get('id', '')
            
            if self.region_filter.should_filter_table(table_id):
                # ä¸ä»…ç§»é™¤è¡¨æ ¼ï¼Œè¿˜è¦ç§»é™¤ç›¸å…³çš„æ ‡é¢˜å’Œæè¿°
                self._remove_table_with_context(table)
                filtered_count += 1
                print(f"  âœ— è¿‡æ»¤è¡¨æ ¼: {table_id}")
            else:
                retained_count += 1
                retained_table_ids.append(table_id)
                print(f"  âœ“ ä¿ç•™è¡¨æ ¼: {table_id}")
        
        print(f"ğŸ“Š è¡¨æ ¼è¿‡æ»¤å®Œæˆ: è¿‡æ»¤{filtered_count}ä¸ªï¼Œä¿ç•™{retained_count}ä¸ª")
        return filtered_count, retained_count, retained_table_ids
    
    def _remove_table_with_context(self, table):
        """
        ç§»é™¤è¡¨æ ¼åŠå…¶ç›¸å…³çš„ä¸Šä¸‹æ–‡ï¼ˆæ ‡é¢˜ã€æè¿°ç­‰ï¼‰
        
        Args:
            table: è¦ç§»é™¤çš„è¡¨æ ¼å…ƒç´ 
        """
        # æŸ¥æ‰¾è¡¨æ ¼å‰é¢çš„ç›¸å…³æ ‡é¢˜
        previous_elements = []
        current = table.previous_sibling
        
        # å‘å‰æŸ¥æ‰¾ç›¸å…³å…ƒç´ ï¼ˆæ ‡é¢˜ã€æ®µè½ç­‰ï¼‰
        while current and len(previous_elements) < 3:  # æœ€å¤šæŸ¥æ‰¾3ä¸ªå‰ç½®å…ƒç´ 
            if hasattr(current, 'name'):
                if current.name in ['h2', 'h3', 'h4', 'h5']:
                    previous_elements.append(current)
                elif current.name == 'p' and len(current.get_text(strip=True)) < 200:
                    # çŸ­æ®µè½å¯èƒ½æ˜¯è¡¨æ ¼æè¿°
                    previous_elements.append(current)
                elif current.name in ['table', 'div']:
                    # é‡åˆ°å…¶ä»–é‡è¦å…ƒç´ ï¼Œåœæ­¢æŸ¥æ‰¾
                    break
            current = current.previous_sibling
        
        # ç§»é™¤ç›¸å…³å…ƒç´ ï¼ˆä»åå¾€å‰ç§»é™¤ï¼Œé¿å…å½±å“siblingå…³ç³»ï¼‰
        for element in reversed(previous_elements):
            if element and hasattr(element, 'decompose'):
                element.decompose()
        
        # æœ€åç§»é™¤è¡¨æ ¼æœ¬èº«
        table.decompose()
    
    def clean_attributes(self, soup: BeautifulSoup, keep_attrs: Optional[List[str]] = None) -> int:
        """
        æ¸…ç†HTMLå±æ€§
        
        Args:
            soup: BeautifulSoupå¯¹è±¡
            keep_attrs: è¦ä¿ç•™çš„å±æ€§åˆ—è¡¨
            
        Returns:
            int: æ¸…ç†çš„å±æ€§æ•°é‡
        """
        if keep_attrs is None:
            keep_attrs = ['id', 'class', 'cellpadding', 'cellspacing', 'width', 'align', 'href', 'src', 'alt', 'title']
        
        cleaned_count = 0
        
        for tag in soup.find_all():
            attrs_to_remove = []
            for attr in tag.attrs:
                if attr not in keep_attrs:
                    attrs_to_remove.append(attr)
                    
            for attr in attrs_to_remove:
                del tag.attrs[attr]
                cleaned_count += 1
        
        return cleaned_count
    
    def extract_content_sections(self, soup: BeautifulSoup) -> Dict[str, BeautifulSoup]:
        """
        æå–é¡µé¢å†…å®¹åŒºå—
        
        Args:
            soup: BeautifulSoupå¯¹è±¡
            
        Returns:
            Dict[str, BeautifulSoup]: å†…å®¹åŒºå—å­—å…¸
        """
        sections = {}
        
        # æå–Banner
        banner = soup.find('div', class_='common-banner')
        if banner:
            sections['banner'] = banner
        
        # æå–å®šä»·è¡¨åŒºåŸŸ
        pricing_sections = soup.find_all('div', class_='pricing-page-section')
        if pricing_sections:
            sections['pricing'] = pricing_sections[0]
        
        # æå–FAQ
        faq_section = soup.find('div', class_='more-detail')
        if faq_section:
            sections['faq'] = faq_section
        
        # æå–SLAï¼ˆæ›´æ™ºèƒ½çš„æŸ¥æ‰¾ï¼‰
        for section in soup.find_all(['div', 'section']):
            if 'æœåŠ¡çº§åˆ«åè®®' in section.get_text() or 'SLA' in section.get_text():
                sections['sla'] = section
                break
        
        return sections
    
    def generate_statistics(self, soup: BeautifulSoup, retained_table_ids: List[str], 
                          filtered_count: int, total_original_tables: int) -> Dict:
        """
        ç”ŸæˆHTMLç»Ÿè®¡ä¿¡æ¯
        
        Args:
            soup: BeautifulSoupå¯¹è±¡
            retained_table_ids: ä¿ç•™çš„è¡¨æ ¼IDåˆ—è¡¨
            filtered_count: è¿‡æ»¤çš„è¡¨æ ¼æ•°é‡
            total_original_tables: åŸå§‹è¡¨æ ¼æ€»æ•°
            
        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        html_content = str(soup)
        
        # ç»Ÿè®¡å„ç§HTMLå…ƒç´ 
        elements_count = {}
        for tag in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p', 'table', 'ul', 'ol', 'a', 'img']:
            elements_count[tag] = len(soup.find_all(tag))
        
        return {
            "ç»Ÿè®¡ä¿¡æ¯": {
                "æ€»å­—ç¬¦æ•°": len(html_content),
                "ä¿ç•™è¡¨æ ¼æ•°": len(retained_table_ids),
                "æ ‡é¢˜æ•°é‡": sum(elements_count[tag] for tag in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']),
                "æ®µè½æ•°é‡": elements_count['p'],
                "åˆ—è¡¨æ•°é‡": elements_count['ul'] + elements_count['ol'],
                "é“¾æ¥æ•°é‡": elements_count['a'],
                "å›¾ç‰‡æ•°é‡": elements_count['img']
            },
            "è¡¨æ ¼ä¿¡æ¯": {
                "ä¿ç•™çš„è¡¨æ ¼ID": retained_table_ids,
                "åŸå§‹è¡¨æ ¼æ•°": total_original_tables,
                "è¿‡æ»¤è¡¨æ ¼æ•°": filtered_count,
                "ä¿ç•™è¡¨æ ¼æ•°": len(retained_table_ids)
            },
            "å†…å®¹åŒºå—": {
                "æœ‰Banner": bool(soup.find('div', class_='common-banner')),
                "æœ‰å®šä»·å†…å®¹": bool(soup.find_all('table')),
                "æœ‰FAQ": bool(soup.find('div', class_='more-detail')),
                "æœ‰SLA": 'æœåŠ¡çº§åˆ«åè®®' in soup.get_text() or 'SLA' in soup.get_text()
            },
            "HTMLç»“æ„": {
                "å…ƒç´ ç»Ÿè®¡": elements_count,
                "å¤„ç†è®°å½•": self.removed_elements_log
            }
        }


class HTMLBuilder:
    """HTMLæ„å»ºå™¨"""
    
    @staticmethod
    def build_clean_html(body_content: str, title: str = "Azureå®šä»·é¡µé¢", region: str = "") -> str:
        """
        æ„å»ºæ¸…ç†åçš„HTMLé¡µé¢
        
        Args:
            body_content: é¡µé¢ä¸»ä½“å†…å®¹
            title: é¡µé¢æ ‡é¢˜
            region: åœ°åŒºä¿¡æ¯
            
        Returns:
            str: å®Œæ•´çš„HTMLå†…å®¹
        """
        full_title = f"{title} - {region}" if region else title
        
        # æ¸…ç†bodyæ ‡ç­¾
        if body_content.strip().startswith('<body'):
            # æå–bodyæ ‡ç­¾å†…çš„å†…å®¹
            start_tag_end = body_content.find('>')
            end_tag_start = body_content.rfind('</body>')
            if start_tag_end != -1 and end_tag_start != -1:
                body_content = body_content[start_tag_end + 1:end_tag_start]
        
        return f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{full_title}</title>
    <meta name="description" content="Azureå®šä»·ä¿¡æ¯ - {region}">
    <meta name="keywords" content="Azure, å®šä»·, {region}">
    <meta name="generator" content="Azure Pricing Extractor v2.0">
    <meta name="extracted-at" content="{datetime.now().isoformat()}">
</head>
<body>
{body_content}
</body>
</html>"""


def validate_html_structure(soup: BeautifulSoup) -> List[str]:
    """
    éªŒè¯HTMLç»“æ„
    
    Args:
        soup: BeautifulSoupå¯¹è±¡
        
    Returns:
        List[str]: éªŒè¯é—®é¢˜åˆ—è¡¨
    """
    issues = []
    
    # æ£€æŸ¥åŸºæœ¬ç»“æ„
    if not soup.find('body') and not soup.find(['div', 'section', 'article']):
        issues.append("ç¼ºå°‘ä¸»è¦å†…å®¹å®¹å™¨")
    
    # æ£€æŸ¥è¡¨æ ¼ç»“æ„
    tables = soup.find_all('table')
    for table in tables:
        table_id = table.get('id', 'æ— ID')
        
        if not table.find('tr'):
            issues.append(f"è¡¨æ ¼ {table_id} ç¼ºå°‘è¡Œ")
            continue
        
        first_row = table.find('tr')
        if first_row and not first_row.find(['th', 'td']):
            issues.append(f"è¡¨æ ¼ {table_id} ç¬¬ä¸€è¡Œç¼ºå°‘å•å…ƒæ ¼")
    
    # æ£€æŸ¥é“¾æ¥
    links = soup.find_all('a')
    js_links = [link for link in links if link.get('href', '').startswith('javascript:')]
    if js_links:
        issues.append(f"å‘ç°{len(js_links)}ä¸ªJavaScripté“¾æ¥ï¼Œå¯èƒ½éœ€è¦æ¸…ç†")
    
    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰tabç›¸å…³ç»“æ„
    tab_elements = soup.find_all(['div'], class_=lambda x: x and any(tab in str(x) for tab in ['tab-', 'dropdown-']))
    if tab_elements:
        issues.append(f"å‘ç°{len(tab_elements)}ä¸ªå¯èƒ½çš„æ®‹ç•™tabå…ƒç´ ")
    
    # æ£€æŸ¥ç©ºç™½å†…å®¹
    text_content = soup.get_text(strip=True)
    if len(text_content) < 100:
        issues.append("é¡µé¢æ–‡æœ¬å†…å®¹è¿‡å°‘ï¼Œå¯èƒ½æå–ä¸å®Œæ•´")
    
    return issues


# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•å‡½æ•°
def test_region_filter():
    """æµ‹è¯•åŒºåŸŸè¿‡æ»¤åŠŸèƒ½"""
    print("=== æµ‹è¯•åŒºåŸŸè¿‡æ»¤åŠŸèƒ½ ===")
    
    # åˆ›å»ºè¿‡æ»¤å™¨
    filter_processor = RegionFilterProcessor("soft-category.json")
    
    # è®¾ç½®æ´»è·ƒåŒºåŸŸ
    filter_processor.set_active_region("north-china3", "Azure Database for MySQL")
    
    # æµ‹è¯•è¡¨æ ¼è¿‡æ»¤
    test_tables = [
        "Azure_Database_For_MySQL5",  # åº”è¯¥ä¿ç•™
        "Azure_Database_For_MySQL6",  # åº”è¯¥è¿‡æ»¤
        "Azure_Database_For_MySQL_IOPS",  # åº”è¯¥ä¿ç•™
        "Azure_Database_For_MySQL_IOPS_East3",  # åº”è¯¥è¿‡æ»¤
    ]
    
    for table_id in test_tables:
        should_filter = filter_processor.should_filter_table(table_id)
        status = "è¿‡æ»¤" if should_filter else "ä¿ç•™"
        print(f"è¡¨æ ¼ {table_id}: {status}")
    
    # æ˜¾ç¤ºå¯ç”¨åŒºåŸŸ
    regions = filter_processor.get_available_regions()
    print(f"å¯ç”¨åŒºåŸŸ: {regions}")


def test_tab_flattening():
    """æµ‹è¯•tabå±•å¼€åŠŸèƒ½"""
    print("=== æµ‹è¯•Tabå±•å¼€åŠŸèƒ½ ===")
    
    # åˆ›å»ºæµ‹è¯•HTML
    test_html = """
    <div class="tab-content">
        <div class="tab-panel" id="tabContent1">
            <h2>å¯çªå¢</h2>
            <p>å…·æœ‰çµæ´»è®¡ç®—è¦æ±‚çš„å·¥ä½œè´Ÿè½½ã€‚</p>
            <table id="test_table_1">
                <tr><th>å®ä¾‹</th><th>ä»·æ ¼</th></tr>
                <tr><td>B1MS</td><td>ï¿¥0.1449/å°æ—¶</td></tr>
            </table>
        </div>
        <div class="tab-panel" id="tabContent2">
            <h2>å¸¸è§„ç”¨é€”</h2>
            <p>å¤§å¤šæ•°ä¸šåŠ¡å·¥ä½œè´Ÿè·ã€‚</p>
            <table id="test_table_2">
                <tr><th>å®ä¾‹</th><th>ä»·æ ¼</th></tr>
                <tr><td>D2ds v4</td><td>ï¿¥1.1220/å°æ—¶</td></tr>
            </table>
        </div>
    </div>
    """
    
    soup = BeautifulSoup(test_html, 'html.parser')
    processor = HTMLProcessor()
    
    print("å±•å¼€å‰çš„ç»“æ„:")
    print(f"  tab-contentæ•°é‡: {len(soup.find_all('div', class_='tab-content'))}")
    print(f"  tab-panelæ•°é‡: {len(soup.find_all('div', class_='tab-panel'))}")
    print(f"  è¡¨æ ¼æ•°é‡: {len(soup.find_all('table'))}")
    
    # æ‰§è¡Œtabå±•å¼€
    processed = processor._flatten_tab_containers(soup)
    
    print(f"\nå±•å¼€åçš„ç»“æ„:")
    print(f"  å¤„ç†çš„å®¹å™¨æ•°: {processed}")
    print(f"  tab-contentæ•°é‡: {len(soup.find_all('div', class_='tab-content'))}")
    print(f"  tab-panelæ•°é‡: {len(soup.find_all('div', class_='tab-panel'))}")
    print(f"  è¡¨æ ¼æ•°é‡: {len(soup.find_all('table'))}")
    print(f"  æ ‡é¢˜æ•°é‡: {len(soup.find_all('h2'))}")
    
    print("\næœ€ç»ˆHTMLç»“æ„:")
    print(soup.prettify())


if __name__ == "__main__":
    test_region_filter()
    print("\n" + "="*50 + "\n")
    test_tab_flattening()