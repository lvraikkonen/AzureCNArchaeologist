#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HTMLå¤„ç†å·¥å…·å‡½æ•°
ä»ContentExtractorä¸­æå–çš„çº¯å·¥å…·å‡½æ•°ï¼Œå»é™¤ä¸šåŠ¡é€»è¾‘ä¾èµ–
"""

import re
from typing import Optional, Set, List
from bs4 import BeautifulSoup, Tag


def create_simple_element(original_element: Tag, soup: BeautifulSoup) -> Optional[Tag]:
    """
    åˆ›å»ºç®€åŒ–çš„å†…å®¹å…ƒç´ ï¼Œå‡å°‘åµŒå¥—
    
    Args:
        original_element: åŸå§‹HTMLå…ƒç´ 
        soup: BeautifulSoupå¯¹è±¡
        
    Returns:
        ç®€åŒ–åçš„HTMLå…ƒç´ 
    """
    if not original_element or not hasattr(original_element, 'name') or not original_element.name:
        return None

    try:
        # åˆ›å»ºæ–°å…ƒç´ 
        new_element = soup.new_tag(original_element.name)

        # åªä¿ç•™æœ€é‡è¦çš„å±æ€§
        if original_element.get('id'):
            new_element['id'] = original_element['id']

        # é’ˆå¯¹ä¸åŒå…ƒç´ ç±»å‹è¿›è¡Œå¤„ç†
        if original_element.name == 'table':
            # è¡¨æ ¼ç‰¹æ®Šå¤„ç†ï¼šä¿æŒå®Œæ•´ç»“æ„
            copy_table_structure(original_element, new_element, soup)

        elif original_element.name == 'a':
            # é“¾æ¥ç‰¹æ®Šå¤„ç†ï¼šä¿ç•™hrefå’Œæ–‡æœ¬
            href = original_element.get('href')
            if href:
                new_element['href'] = href

            # ä¿ç•™aria-labelç­‰å¯è®¿é—®æ€§å±æ€§
            for attr in ['aria-label', 'title', 'target']:
                if original_element.get(attr):
                    new_element[attr] = original_element[attr]

            # å¤åˆ¶é“¾æ¥æ–‡æœ¬
            link_text = original_element.get_text(strip=True)
            if link_text:
                new_element.string = link_text

        elif original_element.name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
            # æ ‡é¢˜ï¼šä¿ç•™æ–‡æœ¬ï¼Œä½†ä¹Ÿæ£€æŸ¥æ˜¯å¦åŒ…å«é“¾æ¥
            if original_element.find('a'):
                # å¦‚æœæ ‡é¢˜ä¸­åŒ…å«é“¾æ¥ï¼Œä¿æŒç»“æ„
                for child in original_element.children:
                    if hasattr(child, 'name') and child.name == 'a':
                        link_element = create_simple_element(child, soup)
                        if link_element:
                            new_element.append(link_element)
                    elif hasattr(child, 'strip'):
                        text = child.strip()
                        if text:
                            new_element.append(text)
            else:
                # æ™®é€šæ ‡é¢˜ï¼Œåªä¿ç•™æ–‡æœ¬
                text_content = original_element.get_text(strip=True)
                if text_content:
                    new_element.string = text_content

        elif original_element.name == 'p':
            # æ®µè½ï¼šå¯èƒ½åŒ…å«é“¾æ¥ï¼Œéœ€è¦ä¿æŒç»“æ„
            if original_element.find('a'):
                # æ®µè½ä¸­åŒ…å«é“¾æ¥ï¼Œä¿æŒæ··åˆå†…å®¹
                for child in original_element.children:
                    if hasattr(child, 'name') and child.name == 'a':
                        link_element = create_simple_element(child, soup)
                        if link_element:
                            new_element.append(link_element)
                    elif hasattr(child, 'strip'):
                        text = child.strip()
                        if text:
                            new_element.append(text)
            else:
                # æ™®é€šæ®µè½ï¼Œåªä¿ç•™æ–‡æœ¬
                text_content = original_element.get_text(strip=True)
                if text_content:
                    new_element.string = text_content

        elif original_element.name in ['ul', 'ol']:
            # åˆ—è¡¨ï¼šä¿ç•™ç»“æ„ä½†ç®€åŒ–
            for li in original_element.find_all('li', recursive=False):
                new_li = soup.new_tag('li')

                # æ£€æŸ¥æ˜¯å¦ä¸ºFAQç»“æ„ - ä½¿ç”¨faq_utils
                from .faq_utils import is_faq_item, process_faq_item

                if is_faq_item(li):
                    # å¤„ç†FAQé¡¹
                    process_faq_item(li, new_li, soup)
                elif li.find('a') and not li.find('i', class_='icon icon-plus'):
                    # æ™®é€šåŒ…å«é“¾æ¥çš„åˆ—è¡¨é¡¹
                    for child in li.children:
                        if hasattr(child, 'name') and child.name == 'a':
                            link_element = create_simple_element(child, soup)
                            if link_element:
                                new_li.append(link_element)
                        elif hasattr(child, 'strip'):
                            text = child.strip()
                            if text:
                                new_li.append(text)
                else:
                    # æ™®é€šåˆ—è¡¨é¡¹
                    li_text = li.get_text(strip=True)
                    if li_text:
                        new_li.string = li_text

                if new_li.get_text(strip=True) or new_li.find_all():
                    new_element.append(new_li)

        else:
            # å…¶ä»–å…ƒç´ ï¼šæå–æ–‡æœ¬å†…å®¹
            text_content = original_element.get_text(strip=True)
            if text_content:
                new_element.string = text_content

        return new_element if (new_element.get_text(strip=True) or new_element.find_all()) else None

    except Exception as e:
        print(f"    âš  åˆ›å»ºç®€åŒ–å…ƒç´ å¤±è´¥: {e}")
        return None


def copy_table_structure(original_table: Tag, new_table: Tag, soup: BeautifulSoup):
    """
    å¤åˆ¶è¡¨æ ¼ç»“æ„ï¼Œç¡®ä¿å®Œæ•´æ€§
    
    Args:
        original_table: åŸå§‹è¡¨æ ¼
        new_table: æ–°è¡¨æ ¼
        soup: BeautifulSoupå¯¹è±¡
    """
    # ç›´æ¥å¤åˆ¶æ‰€æœ‰è¡Œ
    for tr in original_table.find_all('tr'):
        new_tr = soup.new_tag('tr')

        # å¤åˆ¶æ‰€æœ‰å•å…ƒæ ¼
        for cell in tr.find_all(['th', 'td']):
            new_cell = soup.new_tag(cell.name)

            # ä¿ç•™é‡è¦å±æ€§
            for attr in ['colspan', 'rowspan']:
                if cell.get(attr):
                    new_cell[attr] = cell[attr]

            # å¤åˆ¶å•å…ƒæ ¼æ–‡æœ¬
            cell_text = cell.get_text(strip=True)
            if cell_text:
                new_cell.string = cell_text

            new_tr.append(new_cell)

        if new_tr.find_all():  # åªæ·»åŠ éç©ºè¡Œ
            new_table.append(new_tr)


def is_navigation_element(element: Tag) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦ä¸ºå¯¼èˆªå…ƒç´ 
    
    Args:
        element: HTMLå…ƒç´ 
        
    Returns:
        æ˜¯å¦ä¸ºå¯¼èˆªå…ƒç´ 
    """
    if not hasattr(element, 'get'):
        return False

    # æ£€æŸ¥classå±æ€§
    classes = element.get('class', [])
    if isinstance(classes, str):
        classes = [classes]

    navigation_keywords = [
        'nav', 'menu', 'breadcrumb', 'tab-nav', 'dropdown', 'region-container',
        'software-kind', 'header', 'footer', 'sidebar'
    ]

    for class_name in classes:
        if any(keyword in class_name.lower() for keyword in navigation_keywords):
            return True

    return False


def clean_html_content(content: str) -> str:
    """
    æ¸…ç†HTMLå†…å®¹ä¸­çš„å¤šä½™æ ‡ç­¾å’Œç¬¦å·
    
    Args:
        content: åŸå§‹HTMLå†…å®¹
        
    Returns:
        æ¸…ç†åçš„HTMLå†…å®¹
    """
    if not content:
        return content

    # ç§»é™¤å¤šä½™çš„æ¢è¡Œç¬¦å’Œç©ºç™½ç¬¦
    content = re.sub(r'\n+', ' ', content)  # å°†å¤šä¸ªæ¢è¡Œç¬¦æ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼
    content = re.sub(r'\s+', ' ', content)  # å°†å¤šä¸ªç©ºç™½ç¬¦æ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼

    # ç§»é™¤å¤šä½™çš„divæ ‡ç­¾åŒ…è£…ï¼ˆä¿ç•™æœ‰ç”¨çš„classå’Œidï¼‰
    # åªç§»é™¤çº¯ç²¹çš„åŒ…è£…divï¼Œä¿ç•™æœ‰æ„ä¹‰çš„div
    content = re.sub(r'<div>\s*</div>', '', content)  # ç§»é™¤ç©ºçš„divæ ‡ç­¾

    # æ¸…ç†æ ‡ç­¾é—´çš„å¤šä½™ç©ºç™½
    content = re.sub(r'>\s+<', '><', content)  # ç§»é™¤æ ‡ç­¾é—´çš„ç©ºç™½

    # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„ç©ºç™½
    content = content.strip()

    return content


def preprocess_image_paths(soup: BeautifulSoup) -> BeautifulSoup:
    """
    é¢„å¤„ç†å›¾ç‰‡è·¯å¾„ï¼Œæ·»åŠ {img_hostname}å ä½ç¬¦
    
    Args:
        soup: BeautifulSoupå¯¹è±¡
        
    Returns:
        å¤„ç†åçš„BeautifulSoupå¯¹è±¡
    """
    print("ğŸ–¼ï¸ é¢„å¤„ç†å›¾ç‰‡è·¯å¾„...")

    # å¤„ç†imgæ ‡ç­¾çš„srcå±æ€§
    img_count = 0
    for img in soup.find_all('img'):
        src = img.get('src')
        if src and src.startswith('/'):
            img['src'] = f"{{img_hostname}}{src}"
            img_count += 1

    # å¤„ç†styleå±æ€§ä¸­çš„background-image
    style_count = 0
    for element in soup.find_all(style=True):
        style = element.get('style', '')
        if 'background-image:' in style and 'url(' in style:
            # åŒ¹é… url("/path/to/image") æˆ– url('/path/to/image')
            pattern = r'url\(["\']?(/[^"\']*?)["\']?\)'
            def replace_url(match):
                path = match.group(1)
                return f'url("{{{img_hostname}}}{path}")'

            new_style = re.sub(pattern, replace_url, style)
            if new_style != style:
                element['style'] = new_style
                style_count += 1

    # å¤„ç†data-configå±æ€§ä¸­çš„å›¾ç‰‡è·¯å¾„
    data_config_count = 0
    for element in soup.find_all(attrs={'data-config': True}):
        data_config = element.get('data-config', '')
        if data_config and ('backgroundImage' in data_config or 'background-image' in data_config):
            # åŒ¹é… backgroundImage æˆ– background-image åé¢çš„å›¾ç‰‡è·¯å¾„
            pattern = r'(["\'](backgroundImage|background-image)["\']:\s*["\'])(/[^"\']*?)(["\'])'
            def replace_bg_image(match):
                prefix = match.group(1)
                path = match.group(3)
                suffix = match.group(4)
                return f'{prefix}{{img_hostname}}{path}{suffix}'

            new_data_config = re.sub(pattern, replace_bg_image, data_config)
            if new_data_config != data_config:
                element['data-config'] = new_data_config
                data_config_count += 1

    print(f"  âœ“ å¤„ç†äº† {img_count} ä¸ªimgæ ‡ç­¾ã€{style_count} ä¸ªstyleå±æ€§å’Œ {data_config_count} ä¸ªdata-configå±æ€§")

    return soup