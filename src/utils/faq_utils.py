#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FAQå¤„ç†å·¥å…·å‡½æ•°
ä¸“é—¨å¤„ç†FAQç›¸å…³çš„HTMLç»“æ„è¯†åˆ«å’Œç¾åŒ–
"""

from bs4 import BeautifulSoup, Tag


def is_faq_item(li: Tag) -> bool:
    """æ£€æŸ¥æ˜¯å¦ä¸ºFAQé¡¹ç»“æ„"""
    # æ£€æŸ¥æ˜¯å¦æœ‰iconå’Œdivç»“æ„
    has_icon = li.find('i', class_='icon icon-plus')
    has_div = li.find('div')

    if has_icon and has_div:
        # æ£€æŸ¥divå†…æ˜¯å¦æœ‰aæ ‡ç­¾ï¼ˆé—®é¢˜ï¼‰å’Œsectionæ ‡ç­¾ï¼ˆç­”æ¡ˆï¼‰
        div = li.find('div')
        has_question = div.find('a')
        has_answer = div.find('section')

        return bool(has_question and has_answer)

    return False


def process_faq_item(li: Tag, new_li: Tag, soup: BeautifulSoup):
    """å¤„ç†FAQé¡¹ï¼Œæå–é—®é¢˜å’Œç­”æ¡ˆï¼Œä½¿ç”¨ç¾åŒ–çš„HTMLç»“æ„"""
    div = li.find('div')
    if not div:
        return

    # æå–é—®é¢˜
    question_a = div.find('a')
    if question_a:
        question_text = question_a.get_text(strip=True)
        if question_text:
            # åˆ›å»ºé—®é¢˜divå®¹å™¨
            question_div = soup.new_tag('div', **{'class': 'faq-question'})
            question_div.string = question_text
            new_li.append(question_div)

    # æå–ç­”æ¡ˆ
    answer_section = div.find('section')
    if answer_section:
        answer_text = answer_section.get_text(strip=True)
        if answer_text:
            # åˆ›å»ºç­”æ¡ˆdivå®¹å™¨
            answer_div = soup.new_tag('div', **{'class': 'faq-answer'})
            answer_div.string = answer_text
            new_li.append(answer_div)


def extract_qa_content(soup: BeautifulSoup) -> str:
    """æå–Q&Aå†…å®¹ä»¥åŠæ”¯æŒå’ŒæœåŠ¡çº§åˆ«åè®®å†…å®¹"""
    print("ğŸ” æå–Q&Aå†…å®¹...")
    
    qa_sections = []
    
    # æŸ¥æ‰¾å¸¸è§é—®é¢˜éƒ¨åˆ†
    faq_keywords = ['å¸¸è§é—®é¢˜', 'faq', 'frequently asked questions', 'é—®é¢˜è§£ç­”']
    
    for keyword in faq_keywords:
        # æŸ¥æ‰¾åŒ…å«å…³é”®è¯çš„æ ‡é¢˜
        headings = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'], 
                                string=lambda text: text and keyword.lower() in text.lower())
        
        for heading in headings:
            # æŸ¥æ‰¾æ ‡é¢˜åçš„å†…å®¹
            content_element = heading.find_next_sibling()
            
            if content_element:
                qa_text = content_element.get_text(strip=True)
                if qa_text and len(qa_text) > 50:  # è¿‡æ»¤è¿‡çŸ­çš„å†…å®¹
                    qa_sections.append({
                        'section': keyword,
                        'content': qa_text[:1000]  # é™åˆ¶é•¿åº¦
                    })
    
    # æŸ¥æ‰¾æ”¯æŒç›¸å…³å†…å®¹
    support_keywords = ['æ”¯æŒ', 'support', 'æœåŠ¡çº§åˆ«åè®®', 'sla', 'service level']
    
    for keyword in support_keywords:
        elements = soup.find_all(string=lambda text: text and keyword.lower() in text.lower())
        
        for element in elements[:3]:  # é™åˆ¶æ•°é‡
            parent = element.parent
            if parent:
                support_text = parent.get_text(strip=True)
                if support_text and len(support_text) > 30:
                    qa_sections.append({
                        'section': keyword,
                        'content': support_text[:500]
                    })
    
    # åˆå¹¶æ‰€æœ‰Q&Aå†…å®¹
    if qa_sections:
        combined_qa = '\n\n'.join([f"## {section['section']}\n{section['content']}" 
                                  for section in qa_sections[:5]])  # é™åˆ¶ä¸ºå‰5ä¸ª
        print(f"  âœ“ æå–äº† {len(qa_sections)} ä¸ªQ&Aéƒ¨åˆ†")
        return combined_qa
    else:
        print("  âš  æœªæ‰¾åˆ°Q&Aå†…å®¹")
        return ""