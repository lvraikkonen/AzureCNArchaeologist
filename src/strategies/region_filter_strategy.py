#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒºåŸŸç­›é€‰ç­–ç•¥ - é€‚é…æ–°æ¶æ„
å¤„ç†Type Bé¡µé¢ï¼šå…·æœ‰åŒºåŸŸç­›é€‰åŠŸèƒ½çš„é¡µé¢ï¼Œå¦‚API Management
é›†æˆæ–°å·¥å…·ç±»ä¸ç°æœ‰RegionProcessor
"""

import os
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional
from bs4 import BeautifulSoup

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from src.strategies.base_strategy import BaseStrategy
from src.core.region_processor import RegionProcessor
from src.utils.content.content_extractor import ContentExtractor
from src.utils.content.section_extractor import SectionExtractor
from src.utils.content.flexible_builder import FlexibleBuilder
from src.utils.data.extraction_validator import ExtractionValidator
from src.detectors.filter_detector import FilterDetector

from src.core.logging import get_logger

logger = get_logger(__name__)


class RegionFilterStrategy(BaseStrategy):
    """
    åŒºåŸŸç­›é€‰ç­–ç•¥ - æ–°æ¶æ„é€‚é…
    Type B: åŒºåŸŸç­›é€‰é¡µé¢å¤„ç† - API Managementç±»å‹
    
    ç‰¹ç‚¹ï¼š
    - å…·æœ‰åŒºåŸŸç­›é€‰æ§ä»¶ (å¦‚ä¸­å›½åŒ—éƒ¨ã€ä¸­å›½ä¸œéƒ¨ç­‰)
    - ç­›é€‰å™¨å˜åŒ–ä¼šæ”¹å˜å†…å®¹æ˜¾ç¤º
    - éœ€è¦æå–æ¯ä¸ªåŒºåŸŸçš„ä¸“é—¨å†…å®¹
    - ä½¿ç”¨æ–°å·¥å…·ç±»æ¶æ„ï¼šContentExtractor + SectionExtractor + FlexibleBuilder + RegionProcessor
    """

    def __init__(self, product_config: Dict[str, Any], html_file_path: str = ""):
        """
        åˆå§‹åŒ–åŒºåŸŸç­›é€‰ç­–ç•¥
        
        Args:
            product_config: äº§å“é…ç½®ä¿¡æ¯
            html_file_path: HTMLæ–‡ä»¶è·¯å¾„
        """
        super().__init__(product_config, html_file_path)
        self.strategy_name = "region_filter"
        
        # åˆå§‹åŒ–å·¥å…·ç±»
        self.content_extractor = ContentExtractor()
        self.section_extractor = SectionExtractor()
        self.flexible_builder = FlexibleBuilder()
        self.extraction_validator = ExtractionValidator()
        
        # ä¿æŒç°æœ‰åŒºåŸŸå¤„ç†é€»è¾‘
        self.region_processor = RegionProcessor()
        self.filter_detector = FilterDetector()
        
        logger.info(f"ğŸŒ åˆå§‹åŒ–åŒºåŸŸç­›é€‰ç­–ç•¥: {self._get_product_key()}")

    def extract(self, soup: BeautifulSoup, url: str = "") -> Dict[str, Any]:
        """
        æ‰§è¡Œä¼ ç»ŸCMSæ ¼å¼æå–é€»è¾‘ï¼ˆå‘åå…¼å®¹ï¼‰
        
        Args:
            soup: BeautifulSoupè§£æçš„HTMLå¯¹è±¡
            url: æºURL
            
        Returns:
            ä¼ ç»ŸCMSæ ¼å¼çš„æå–æ•°æ®ï¼ŒåŒ…å«åŒºåŸŸç‰¹å®šå†…å®¹
        """
        logger.info("ğŸŒ æ‰§è¡ŒåŒºåŸŸç­›é€‰ç­–ç•¥æå–ï¼ˆä¼ ç»ŸCMSæ ¼å¼ï¼‰...")
        
        # 1. ä½¿ç”¨ContentExtractoræå–åŸºç¡€å…ƒæ•°æ®
        base_content = self.content_extractor.extract_base_metadata(soup, url, self.html_file_path)
        
        # 2. ä½¿ç”¨SectionExtractoræå–sectionså†…å®¹
        sections = self.section_extractor.extract_all_sections(soup)
        
        # è½¬æ¢sectionsä¸ºä¼ ç»ŸCMSæ ¼å¼
        for section in sections:
            section_type = section.get("sectionType", "")
            content = section.get("content", "")
            
            if section_type == "Banner":
                base_content["BannerContent"] = content
            elif section_type == "Description":
                base_content["DescriptionContent"] = content
            elif section_type == "Qa":
                base_content["QaContent"] = content
        
        # 3. è·å–ç­›é€‰å™¨ä¿¡æ¯ç”¨äºåŒºåŸŸå¤„ç†
        filter_analysis = self.filter_detector.detect_filters(soup)
        
        # 4. ä½¿ç”¨RegionProcessorè¿›è¡ŒåŒºåŸŸå¤„ç†ï¼ˆä¼ é€’ç­›é€‰å™¨ä¿¡æ¯å’Œäº§å“é…ç½®ï¼‰
        try:
            region_content = self.region_processor.extract_region_contents(
                soup, 
                self.html_file_path,
                filter_analysis=filter_analysis,
                product_config=self.product_config
            )
            logger.info(f"ğŸŒ åŒºåŸŸå†…å®¹æå–å®Œæˆ: {len(region_content)} ä¸ªåŒºåŸŸ")
        except Exception as e:
            logger.warning(f"âš  åŒºåŸŸå†…å®¹æå–å¤±è´¥: {e}")
            region_content = {}
        
        # 5. è½¬æ¢åŒºåŸŸå†…å®¹ä¸ºCMSæ ¼å¼
        cms_fields = self._convert_region_content_to_cms_format(region_content)
        
        # 6. ç»„åˆæœ€ç»ˆç»“æœ
        final_data = {
            **base_content,
            **cms_fields,
            "HasRegion": True,
            "RegionalContent": region_content,
            "extraction_strategy": "region_filter",
            "region_count": len(region_content),
            "supported_regions": list(region_content.keys()) if region_content else [],
            "PricingTables": [],
            "ServiceTiers": []
        }
        
        # 7. éªŒè¯æå–ç»“æœ
        final_data = self.extraction_validator.validate_cms_extraction(final_data, self.product_config)
        
        logger.info("âœ… åŒºåŸŸç­›é€‰ç­–ç•¥æå–å®Œæˆï¼ˆä¼ ç»ŸCMSæ ¼å¼ï¼‰")
        return final_data

    def extract_flexible_content(self, soup: BeautifulSoup, url: str = "") -> Dict[str, Any]:
        """
        æ‰§è¡Œflexible JSONæ ¼å¼æå–é€»è¾‘
        
        Args:
            soup: BeautifulSoupè§£æçš„HTMLå¯¹è±¡
            url: æºURL
            
        Returns:
            flexible JSONæ ¼å¼çš„æå–æ•°æ®
        """
        logger.info("ğŸŒ æ‰§è¡ŒåŒºåŸŸç­›é€‰ç­–ç•¥æå–ï¼ˆflexible JSONæ ¼å¼ï¼‰...")
        
        # 1. ä½¿ç”¨ContentExtractoræå–åŸºç¡€å…ƒæ•°æ®
        base_metadata = self.content_extractor.extract_base_metadata(soup, url, self.html_file_path)
        
        # 2. ä½¿ç”¨SectionExtractoræå–commonSections
        common_sections = self.section_extractor.extract_all_sections(soup)
        
        # 3. ä½¿ç”¨FilterDetectorè·å–ç­›é€‰å™¨ä¿¡æ¯
        filter_analysis = self.filter_detector.detect_filters(soup)
        
        # 4. ä½¿ç”¨RegionProcessoræå–åŒºåŸŸå†…å®¹ï¼ˆä¼ é€’ç­›é€‰å™¨ä¿¡æ¯å’Œäº§å“é…ç½®ï¼‰
        try:
            region_content = self.region_processor.extract_region_contents(
                soup, 
                self.html_file_path,
                filter_analysis=filter_analysis,
                product_config=self.product_config
            )
            logger.info(f"âœ… åŒºåŸŸå†…å®¹æå–å®Œæˆ: {len(region_content)} ä¸ªåŒºåŸŸ")
        except Exception as e:
            logger.warning(f"âš  åŒºåŸŸå†…å®¹æå–å¤±è´¥: {e}")
            region_content = {}
        
        # 5. ä½¿ç”¨FlexibleBuilderæ„å»ºåœ°åŒºå†…å®¹ç»„
        content_groups = self.flexible_builder.build_region_content_groups(region_content)
        
        # 6. æ„å»ºé¡µé¢é…ç½®
        page_config = self.flexible_builder.build_page_config(filter_analysis)
        
        # 7. æ„å»ºç­–ç•¥ç‰¹å®šå†…å®¹
        strategy_content = {
            "baseContent": "",  # åŒºåŸŸç­›é€‰é¡µé¢ä¸»è¦å†…å®¹åœ¨contentGroupsä¸­
            "contentGroups": content_groups,
            "pageConfig": page_config,
            "strategy_type": "region_filter"
        }
        
        # 8. ä½¿ç”¨FlexibleBuilderæ„å»ºå®Œæ•´çš„flexible JSON
        flexible_data = self.flexible_builder.build_flexible_page(
            base_metadata, common_sections, strategy_content
        )
        
        # 9. éªŒè¯flexible JSONç»“æœ
        flexible_data = self.extraction_validator.validate_flexible_json(flexible_data)
        
        logger.info("âœ… åŒºåŸŸç­›é€‰ç­–ç•¥æå–å®Œæˆï¼ˆflexible JSONæ ¼å¼ï¼‰")
        return flexible_data

    def extract_common_sections(self, soup: BeautifulSoup) -> List[Dict[str, str]]:
        """
        æå–é€šç”¨sectionsï¼ˆBannerã€Descriptionã€QAç­‰ï¼‰
        
        Args:
            soup: BeautifulSoupè§£æçš„HTMLå¯¹è±¡
            
        Returns:
            commonSectionsåˆ—è¡¨
        """
        return self.section_extractor.extract_all_sections(soup)

    def _convert_region_content_to_cms_format(self, region_content: Dict[str, Any]) -> Dict[str, str]:
        """
        è½¬æ¢åŒºåŸŸå†…å®¹ä¸ºCMSæ ¼å¼å­—æ®µ - ç”Ÿæˆç»“æ„åŒ–HTMLæ ¼å¼
        
        Args:
            region_content: RegionProcessoræå–çš„åŒºåŸŸå†…å®¹
            
        Returns:
            CMSæ ¼å¼çš„åŒºåŸŸå­—æ®µæ˜ å°„
        """
        cms_fields = {}
        
        # åŒºåŸŸIDåˆ°CMSå­—æ®µçš„æ˜ å°„
        region_mapping = {
            "north-china": "NorthChinaContent",
            "east-china": "EastChinaContent", 
            "north-china2": "NorthChina2Content",
            "east-china2": "EastChina2Content",
            "north-china3": "NorthChina3Content",
            # å¯ä»¥æ ¹æ®éœ€è¦æ‰©å±•æ›´å¤šåŒºåŸŸ
        }
        
        for region_id, content in region_content.items():
            field_name = region_mapping.get(region_id, f"{region_id.replace('-', '_').title()}Content")
            
            # è½¬æ¢ä¸ºç»“æ„åŒ–HTMLæ ¼å¼
            html_content = self._format_region_content_as_html(content, region_id)
            cms_fields[field_name] = html_content
        
        logger.info(f"ğŸ”„ åŒºåŸŸå†…å®¹è½¬æ¢å®Œæˆ: {len(cms_fields)} ä¸ªCMSå­—æ®µ")
        return cms_fields
    
    def _format_region_content_as_html(self, content, region_id: str) -> str:
        """
        å°†åŒºåŸŸå†…å®¹æ ¼å¼åŒ–ä¸ºHTMLç»“æ„ - æ”¯æŒæ–°çš„HTMLå­—ç¬¦ä¸²æ ¼å¼
        
        Args:
            content: åŒºåŸŸå†…å®¹ï¼ˆå¯èƒ½æ˜¯å­—å…¸æˆ–HTMLå­—ç¬¦ä¸²ï¼‰
            region_id: åŒºåŸŸID
            
        Returns:
            æ ¼å¼åŒ–çš„HTMLå­—ç¬¦ä¸²
        """
        # æ–°æ ¼å¼ï¼šå¦‚æœcontentå·²ç»æ˜¯HTMLå­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
        if isinstance(content, str):
            logger.info(f"    ğŸ“„ ä½¿ç”¨HTMLå­—ç¬¦ä¸²æ ¼å¼ï¼Œé•¿åº¦: {len(content)}")
            return content
        
        # æ—§æ ¼å¼ï¼šå¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼ŒæŒ‰åŸæ¥çš„é€»è¾‘å¤„ç†
        if isinstance(content, dict):
            logger.info(f"    ğŸ“Š ä½¿ç”¨å­—å…¸æ ¼å¼ï¼ŒåŒ…å«: {list(content.keys())}")
            return self._format_region_dict_as_html(content, region_id)
        
        # å›é€€æƒ…å†µ
        logger.info(f"    âš  æœªçŸ¥å†…å®¹æ ¼å¼: {type(content)}")
        return str(content)

    def _format_region_dict_as_html(self, content: Dict[str, Any], region_id: str) -> str:
        """
        å°†åŒºåŸŸå­—å…¸å†…å®¹æ ¼å¼åŒ–ä¸ºHTMLç»“æ„ï¼ˆåŸé€»è¾‘ä¿æŒä¸å˜ï¼‰
        
        Args:
            content: åŒºåŸŸå†…å®¹å­—å…¸
            region_id: åŒºåŸŸID
            
        Returns:
            æ ¼å¼åŒ–çš„HTMLå­—ç¬¦ä¸²
        """
        html_parts = []
        
        try:
            # 1. å®šä»·è¡¨æ ¼éƒ¨åˆ†
            if 'pricing_tables' in content and content['pricing_tables']:
                pricing_html = "<div class='pricing-tables'>"
                for table in content['pricing_tables']:
                    if isinstance(table, dict) and 'content' in table:
                        # æ¸…ç†å†…å®¹ï¼Œç§»é™¤å¤šä½™çš„æ¢è¡Œå’Œç©ºæ ¼
                        table_content = self._clean_content(table['content'])
                        pricing_html += f" {table_content}"
                pricing_html += " </div>"
                html_parts.append(pricing_html)
            
            # 2. FAQ/åŠŸèƒ½å¯ç”¨æ€§éƒ¨åˆ†  
            if 'feature_availability' in content and content['feature_availability']:
                faq_html = "<div class='feature-availability'>"
                for faq in content['feature_availability']:
                    cleaned_faq = self._clean_content(faq)
                    faq_html += f"<p>{cleaned_faq}</p>"
                faq_html += "</div>"
                html_parts.append(faq_html)
            
            # 3. åŒºåŸŸè¯´æ˜éƒ¨åˆ†
            if 'region_notes' in content and content['region_notes']:
                notes_html = "<div class='region-notes'>"
                for note in content['region_notes']:
                    cleaned_note = self._clean_content(note)
                    notes_html += f"<p>{cleaned_note}</p>"
                notes_html += "</div>"
                html_parts.append(notes_html)
                
            # å¦‚æœæ²¡æœ‰ç»“æ„åŒ–æ•°æ®ï¼Œå°è¯•å¤„ç†åŸå§‹å†…å®¹
            if not html_parts and isinstance(content, dict):
                if 'content' in content:
                    cleaned_content = self._clean_content(content['content'])
                    html_parts.append(f"<div class='pricing-content'>{cleaned_content}</div>")
                elif 'html' in content:
                    cleaned_html = self._clean_content(content['html'])
                    html_parts.append(cleaned_html)
            
            return "".join(html_parts)
            
        except Exception as e:
            logger.info(f"âš  åŒºåŸŸå†…å®¹HTMLæ ¼å¼åŒ–å¤±è´¥ ({region_id}): {e}")
            # å›é€€åˆ°ç®€å•å­—ç¬¦ä¸²å¤„ç†
            if isinstance(content, dict):
                return self._clean_content(str(content))
            else:
                return self._clean_content(str(content))
    
    def _clean_content(self, content: str) -> str:
        """
        æ¸…ç†å†…å®¹ï¼Œç§»é™¤å¤šä½™çš„æ ‡ç­¾å’Œç¬¦å·
        
        Args:
            content: åŸå§‹å†…å®¹å­—ç¬¦ä¸²
            
        Returns:
            æ¸…ç†åçš„å†…å®¹
        """
        if not content:
            return ""
        
        import re
        
        # ç§»é™¤å¤šä½™çš„æ¢è¡Œç¬¦å’Œç©ºæ ¼
        content = re.sub(r'\s+', ' ', content.strip())
        
        # ç§»é™¤ä¸å¿…è¦çš„divæ ‡ç­¾ï¼ˆä¿ç•™classçš„divï¼‰
        content = re.sub(r'<div(?!\s+class=)[^>]*>', '', content)
        content = re.sub(r'</div>', '', content)
        
        # ç§»é™¤ç©ºçš„æ®µè½å’Œå¤šä½™çš„æ ‡ç­¾
        content = re.sub(r'<p>\s*</p>', '', content)
        content = re.sub(r'<span[^>]*></span>', '', content)
        
        # æ¸…ç†å¤šä½™çš„ç©ºæ ¼
        content = re.sub(r'\s+', ' ', content.strip())
        
        return content

    def _extract_base_content(self, soup: BeautifulSoup, url: str = "") -> Dict[str, Any]:
        """
        é‡å†™åŸºç¡€å†…å®¹æå–ï¼Œé’ˆå¯¹åŒºåŸŸç­›é€‰é¡µé¢è¿›è¡Œä¼˜åŒ–
        """
        print("ğŸ” æå–åŒºåŸŸç­›é€‰é¡µé¢åŸºç¡€å†…å®¹...")
        
        # è°ƒç”¨çˆ¶ç±»æ–¹æ³•è·å–åŸºç¡€å†…å®¹
        base_content = super()._extract_base_content(soup, url)
        
        # ä¸ºåŒºåŸŸç­›é€‰é¡µé¢æ·»åŠ ç‰¹æ®Šå¤„ç†
        base_content["page_type"] = "region_filter"
        base_content["has_region_filter"] = True
        
        # æ£€æµ‹åŒºåŸŸç­›é€‰å™¨çš„å­˜åœ¨
        region_filter_indicators = [
            '.region-selector',
            '.region-filter',
            '[data-region-filter]',
            'select[data-region]',
            '.dropdown-region'
        ]
        
        region_filter_found = False
        for selector in region_filter_indicators:
            if soup.select_one(selector):
                region_filter_found = True
                break
        
        base_content["region_filter_detected"] = region_filter_found
        
        return base_content

    def _get_product_key(self) -> str:
        """è·å–äº§å“é”®"""
        if hasattr(self, 'product_config') and 'product_key' in self.product_config:
            return self.product_config['product_key']
        
        # ä»æ–‡ä»¶è·¯å¾„æ¨æ–­
        if self.html_file_path:
            file_name = Path(self.html_file_path).stem
            if file_name.endswith('-index'):
                return file_name[:-6]
        
        return "unknown"