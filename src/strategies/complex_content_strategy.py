#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤æ‚å†…å®¹ç­–ç•¥ - åŸºäºæ–°æ¶æ„åˆ›å»º
å¤„ç†å¤æ‚çš„å¤šç­›é€‰å™¨å’Œtabç»„åˆï¼Œå¦‚Cloud Servicesç±»å‹é¡µé¢
å…¨æ–°å®ç°ï¼ŒåŸºäºæ–°å·¥å…·ç±»æ¶æ„
"""

import os
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional
from bs4 import BeautifulSoup

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from src.strategies.base_strategy import BaseStrategy
from src.core.region_processor import RegionProcessor
from src.utils.content.content_extractor import ContentExtractor
from src.utils.content.section_extractor import SectionExtractor
from src.utils.content.flexible_builder import FlexibleBuilder
from src.utils.data.extraction_validator import ExtractionValidator
from src.detectors.filter_detector import FilterDetector
from src.detectors.tab_detector import TabDetector
from src.core.logging import get_logger

logger = get_logger(__name__)


class ComplexContentStrategy(BaseStrategy):
    """
    å¤æ‚å†…å®¹ç­–ç•¥ - æ–°æ¶æ„å®ç°
    Type C: å¤æ‚é¡µé¢å¤„ç† - Cloud Servicesç±»å‹
    
    ç‰¹ç‚¹ï¼š
    - å…·æœ‰å¤šç§ç­›é€‰å™¨ç»„åˆï¼šè½¯ä»¶ç±»åˆ«ã€åœ°åŒºã€category tabsç­‰
    - å¤æ‚çš„äº¤äº’å’Œå†…å®¹æ˜ å°„å…³ç³»
    - éœ€è¦å¤„ç†å¤šç»´åº¦å†…å®¹ç»„åˆ
    - ä½¿ç”¨æ–°å·¥å…·ç±»æ¶æ„ï¼šContentExtractor + SectionExtractor + FlexibleBuilder + FilterDetector + TabDetector
    """

    def __init__(self, product_config: Dict[str, Any], html_file_path: str = ""):
        """
        åˆå§‹åŒ–å¤æ‚å†…å®¹ç­–ç•¥
        
        Args:
            product_config: äº§å“é…ç½®ä¿¡æ¯
            html_file_path: HTMLæ–‡ä»¶è·¯å¾„
        """
        super().__init__(product_config, html_file_path)
        self.strategy_name = "complex_content"
        
        # åˆå§‹åŒ–å·¥å…·ç±»
        self.content_extractor = ContentExtractor()
        self.section_extractor = SectionExtractor()
        self.flexible_builder = FlexibleBuilder()
        self.extraction_validator = ExtractionValidator()
        
        # åˆå§‹åŒ–æ£€æµ‹å™¨
        self.filter_detector = FilterDetector()
        self.tab_detector = TabDetector()
        
        # åˆå§‹åŒ–åŒºåŸŸå¤„ç†å™¨ï¼ˆç”¨äºè¡¨æ ¼ç­›é€‰ï¼‰
        self.region_processor = RegionProcessor()
        
        logger.info(f"ğŸ”§ åˆå§‹åŒ–å¤æ‚å†…å®¹ç­–ç•¥: {self._get_product_key()}")

    def extract_flexible_content(self, soup: BeautifulSoup, url: str = "") -> Dict[str, Any]:
        """
        æ‰§è¡Œflexible JSONæ ¼å¼æå–é€»è¾‘
        
        Args:
            soup: BeautifulSoupè§£æçš„HTMLå¯¹è±¡
            url: æºURL
            
        Returns:
            flexible JSONæ ¼å¼çš„æå–æ•°æ®
        """
        logger.info("ğŸ”§ å¼€å§‹å¤æ‚å†…å®¹ç­–ç•¥æå–ï¼ˆflexible JSONæ ¼å¼ï¼‰...")
        
        # 1. ä½¿ç”¨ContentExtractoræå–åŸºç¡€å…ƒæ•°æ®
        base_metadata = self.content_extractor.extract_base_metadata(soup, url, self.html_file_path)
        
        # 2. ä½¿ç”¨SectionExtractoræå–commonSections
        common_sections = self.section_extractor.extract_all_sections(soup)
        
        # 3. åˆ†æç­›é€‰å™¨å’Œtabç»“æ„
        filter_analysis = self.filter_detector.detect_filters(soup)
        tab_analysis = self.tab_detector.detect_tabs(soup)
        
        # 4. æå–å¤æ‚å†…å®¹æ˜ å°„
        content_mapping = self._extract_complex_content_mapping(soup, filter_analysis, tab_analysis)
        
        # 5. ä½¿ç”¨FlexibleBuilderæ„å»ºå¤æ‚å†…å®¹ç»„
        content_groups = self.flexible_builder.build_complex_content_groups(
            filter_analysis, tab_analysis, content_mapping
        )

        # 6. æ„å»ºç­–ç•¥ç‰¹å®šå†…å®¹
        strategy_content = {
            "baseContent": "",  # å¤æ‚é¡µé¢ä¸»è¦å†…å®¹åœ¨contentGroupsä¸­
            "contentGroups": content_groups,
            "strategy_type": "complex",
            "filter_analysis": filter_analysis,  # ä¼ é€’ç­›é€‰å™¨åˆ†æç»“æœ
            "tab_analysis": tab_analysis  # ä¼ é€’tabåˆ†æç»“æœ
        }
        
        # 7. ä½¿ç”¨FlexibleBuilderæ„å»ºå®Œæ•´çš„flexible JSON
        flexible_data = self.flexible_builder.build_flexible_page(
            base_metadata, common_sections, strategy_content
        )
        
        # 8. éªŒè¯flexible JSONç»“æœ
        flexible_data = self.extraction_validator.validate_flexible_json(flexible_data)
        
        logger.info("âœ… å¤æ‚å†…å®¹ç­–ç•¥æå–å®Œæˆï¼ˆflexible JSONæ ¼å¼ï¼‰")
        return flexible_data

    def extract_common_sections(self, soup: BeautifulSoup) -> List[Dict[str, str]]:
        """
        æå–é€šç”¨sectionsï¼ˆBannerã€Descriptionã€QAç­‰ï¼‰
        
        Args:
            soup: BeautifulSoupè§£æçš„HTMLå¯¹è±¡
            
        Returns:
            commonSectionsåˆ—è¡¨
        """
        return self.section_extractor.extract_all_sections(soup)

    def _extract_complex_main_content(self, soup: BeautifulSoup, 
                                    filter_analysis: Dict[str, Any], 
                                    tab_analysis: Dict[str, Any]) -> str:
        """
        æå–å¤æ‚é¡µé¢çš„ä¸»è¦å†…å®¹ï¼ˆç®€åŒ–ç‰ˆï¼Œç”¨äºä¼ ç»ŸCMSæ ¼å¼ï¼‰
        
        Args:
            soup: BeautifulSoupå¯¹è±¡
            filter_analysis: ç­›é€‰å™¨åˆ†æç»“æœ
            tab_analysis: Tabåˆ†æç»“æœ
            
        Returns:
            ä¸»è¦å†…å®¹HTMLå­—ç¬¦ä¸²
        """
        logger.info("ğŸ“ æå–å¤æ‚é¡µé¢ä¸»è¦å†…å®¹...")
        
        try:
            main_content = ""
            
            # 1. ä¼˜å…ˆæŸ¥æ‰¾technical-azure-selectorä¸»å®¹å™¨
            main_container = soup.find('div', class_='technical-azure-selector')
            if main_container:
                # è·å–æ‰€æœ‰å†…å®¹ç»„ï¼ˆtabContentåˆ†ç»„ï¼‰
                content_groups = tab_analysis.get("content_groups", [])
                
                if content_groups:
                    # æå–ç¬¬ä¸€ä¸ªå†…å®¹ç»„çš„å†…å®¹ä½œä¸ºç¤ºä¾‹
                    first_group = content_groups[0]
                    group_id = first_group.get("id", "")
                    
                    group_element = soup.find('div', id=group_id)
                    if group_element:
                        # è¿‡æ»¤QAç­‰é‡å¤å†…å®¹
                        content_text = group_element.get_text().lower()
                        if not any(skip_text in content_text for skip_text in [
                            'å¸¸è§é—®é¢˜', 'faq', 'æ”¯æŒå’ŒæœåŠ¡çº§åˆ«åè®®'
                        ]):
                            main_content = str(group_element)
                            logger.info(f"âœ“ æ‰¾åˆ°å¤æ‚é¡µé¢ä¸»å®¹å™¨å†…å®¹ï¼ˆ{group_id}ï¼‰")
                            return main_content
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ†ç»„ï¼Œè¿”å›æ•´ä¸ªä¸»å®¹å™¨
                main_content = str(main_container)
                logger.info("âœ“ æ‰¾åˆ°å¤æ‚é¡µé¢ä¸»å®¹å™¨å†…å®¹ï¼ˆå®Œæ•´ï¼‰")
                return main_content
            
            # 2. å¤‡ç”¨æ–¹æ¡ˆï¼šæŸ¥æ‰¾pricing-page-section
            pricing_sections = soup.find_all('div', class_='pricing-page-section')
            if pricing_sections:
                for i, section in enumerate(pricing_sections):
                    if i > 0:  # è·³è¿‡ç¬¬ä¸€ä¸ªï¼ˆé€šå¸¸æ˜¯æè¿°ï¼‰
                        section_text = section.get_text().lower()
                        if not any(skip_text in section_text for skip_text in [
                            'banner', 'navigation', 'nav', 'å¸¸è§é—®é¢˜', 'faq'
                        ]):
                            main_content += str(section)
                
                if main_content:
                    logger.info("âœ“ ä½¿ç”¨pricing-page-sectionå¤‡ç”¨æ–¹æ¡ˆ")
                    return main_content
            
            # 3. æœ€åå¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ContentExtractor
            main_content = self.content_extractor.extract_main_content(soup)
            if main_content:
                logger.info("âœ“ ä½¿ç”¨ContentExtractorå¤‡ç”¨æ–¹æ¡ˆ")
                return main_content
            
            logger.info("âš  æœªæ‰¾åˆ°åˆé€‚çš„å¤æ‚é¡µé¢ä¸»è¦å†…å®¹")
            return ""
            
        except Exception as e:
            logger.info(f"âš  å¤æ‚é¡µé¢ä¸»è¦å†…å®¹æå–å¤±è´¥: {e}")
            return ""

    def _extract_complex_content_mapping(self, soup: BeautifulSoup,
                                       filter_analysis: Dict[str, Any],
                                       tab_analysis: Dict[str, Any]) -> Dict[str, str]:
        """
        æå–å¤æ‚é¡µé¢çš„å†…å®¹æ˜ å°„å…³ç³»ï¼ˆå¸¦åŒºåŸŸç­›é€‰ï¼‰
        
        Args:
            soup: BeautifulSoupå¯¹è±¡
            filter_analysis: ç­›é€‰å™¨åˆ†æç»“æœ
            tab_analysis: Tabåˆ†æç»“æœ
            
        Returns:
            å†…å®¹æ˜ å°„å­—å…¸
        """
        logger.info("ğŸ—ºï¸ æå–å¤æ‚é¡µé¢å†…å®¹æ˜ å°„ï¼ˆæ”¯æŒåŒºåŸŸç­›é€‰ï¼‰...")
        
        content_mapping = {}
        
        try:
            # è·å–ç”¨äºåŒºåŸŸç­›é€‰çš„OSåç§°
            os_name = self.region_processor.get_os_name_for_region_filtering(
                product_config=self.product_config,
                filter_analysis=filter_analysis,
                html_file_path=self.html_file_path
            )
            
            if not os_name:
                logger.warning("âš  æ— æ³•è·å–æœ‰æ•ˆçš„OSåç§°ï¼Œå°†è·³è¿‡åŒºåŸŸè¡¨æ ¼ç­›é€‰")
            else:
                logger.info(f"ğŸ¯ ä½¿ç”¨OSåç§° '{os_name}' è¿›è¡ŒåŒºåŸŸè¡¨æ ¼ç­›é€‰")
            
            # è·å–regioné€‰é¡¹
            region_options = filter_analysis.get("region_options", [])
            software_options = filter_analysis.get("software_options", [])
            category_tabs = tab_analysis.get("category_tabs", [])
            
            # å¦‚æœæ²¡æœ‰åŒºåŸŸé€‰é¡¹ï¼Œä½¿ç”¨é»˜è®¤
            if not region_options:
                region_options = [{"value": "default", "label": "é»˜è®¤"}]
            
            # æ„å»ºå¤šç»´åº¦æ˜ å°„
            for region in region_options:
                region_id = region.get("value", "")
                
                if software_options:
                    # æœ‰è½¯ä»¶ç­›é€‰å™¨çš„æƒ…å†µ
                    for software in software_options:
                        software_id = software.get("value", "")
                        
                        if category_tabs:
                            # æœ‰category tabsçš„æƒ…å†µ - ä¸‰ç»´æ˜ å°„
                            for tab in category_tabs:
                                tab_id = tab.get("href", "").replace("#", "")
                                content_key = f"{region_id}_{software_id}_{tab_id}"
                                
                                # å°è¯•æ‰¾åˆ°å¯¹åº”çš„å†…å®¹å¹¶åº”ç”¨åŒºåŸŸç­›é€‰
                                content = self._find_content_by_mapping(soup, region_id, software_id, tab_id, os_name)
                                if content:
                                    content_mapping[content_key] = content
                        else:
                            # åªæœ‰region + software - äºŒç»´æ˜ å°„
                            content_key = f"{region_id}_{software_id}"
                            content = self._find_content_by_mapping(soup, region_id, software_id, None, os_name)
                            if content:
                                content_mapping[content_key] = content
                elif category_tabs:
                    # åªæœ‰region + category tabs - äºŒç»´æ˜ å°„
                    for tab in category_tabs:
                        tab_id = tab.get("href", "").replace("#", "")
                        content_key = f"{region_id}_{tab_id}"
                        content = self._find_content_by_mapping(soup, region_id, None, tab_id, os_name)
                        if content:
                            content_mapping[content_key] = content
                else:
                    # åªæœ‰region - ä¸€ç»´æ˜ å°„
                    content_key = region_id
                    content = self._find_content_by_mapping(soup, region_id, None, None, os_name)
                    if content:
                        content_mapping[content_key] = content
            
            logger.info(f"âœ“ æ„å»ºäº† {len(content_mapping)} ä¸ªå†…å®¹æ˜ å°„")
            return content_mapping
            
        except Exception as e:
            logger.info(f"âš  å†…å®¹æ˜ å°„æå–å¤±è´¥: {e}")
            return {}

    def _find_content_by_mapping(self, soup: BeautifulSoup, 
                               region_id: str = None,
                               software_id: str = None, 
                               tab_id: str = None,
                               os_name: str = None) -> str:
        """
        æ ¹æ®æ˜ å°„å…³ç³»æŸ¥æ‰¾å¯¹åº”å†…å®¹ï¼ˆæ”¯æŒåŒºåŸŸè¡¨æ ¼ç­›é€‰ï¼‰
        
        Args:
            soup: BeautifulSoupå¯¹è±¡
            region_id: åŒºåŸŸID
            software_id: è½¯ä»¶ID
            tab_id: Tab ID
            os_name: OSåç§°ï¼Œç”¨äºåŒºåŸŸç­›é€‰
            
        Returns:
            æ‰¾åˆ°çš„å†…å®¹HTMLå­—ç¬¦ä¸²ï¼ˆç»è¿‡åŒºåŸŸç­›é€‰ï¼‰
        """
        try:
            # é¦–å…ˆä»åŸå§‹soupä¸­æ‰¾åˆ°åŸºç¡€å†…å®¹
            base_content = None
            
            # 1. å¦‚æœæœ‰tab_idï¼Œä¼˜å…ˆæŸ¥æ‰¾tabå¯¹åº”å†…å®¹
            if tab_id:
                base_content = soup.find('div', id=tab_id)
                if base_content:
                    logger.info(f"âœ“ æ‰¾åˆ°tabå†…å®¹: {tab_id}")
            
            # 2. å¦‚æœæœ‰software_idï¼ŒæŸ¥æ‰¾å¯¹åº”çš„tabContentåˆ†ç»„
            if not base_content and software_id:
                content_groups = soup.find_all('div', class_='tab-panel')
                for group in content_groups:
                    group_id = group.get('id', '')
                    if 'tabContent' in group_id:
                        base_content = group
                        logger.info(f"âœ“ æ‰¾åˆ°è½¯ä»¶å†…å®¹ç»„: {group_id}")
                        break
            
            # 3. é»˜è®¤è¿”å›ä¸»è¦å†…å®¹åŒºåŸŸ
            if not base_content:
                base_content = soup.find('div', class_='technical-azure-selector')
                if base_content:
                    logger.info("âœ“ ä½¿ç”¨ä¸»è¦å†…å®¹åŒºåŸŸ")
            
            if not base_content:
                logger.warning("âš  æœªæ‰¾åˆ°ä»»ä½•åŸºç¡€å†…å®¹")
                return ""
            
            # åº”ç”¨åŒºåŸŸç­›é€‰ï¼ˆå¦‚æœæœ‰region_idå’Œos_nameï¼‰
            if region_id and os_name:
                logger.info(f"ğŸ” å¯¹å†…å®¹åº”ç”¨åŒºåŸŸç­›é€‰: region={region_id}, os={os_name}")
                # åˆ›å»ºåŒ…å«æ‰¾åˆ°å†…å®¹çš„ä¸´æ—¶soup
                temp_soup = BeautifulSoup(str(base_content), 'html.parser')
                # åº”ç”¨åŒºåŸŸç­›é€‰
                filtered_soup = self.region_processor.apply_region_filtering(temp_soup, region_id, os_name)
                return str(filtered_soup)
            else:
                # æ²¡æœ‰åŒºåŸŸä¿¡æ¯ï¼Œç›´æ¥è¿”å›åŸå§‹å†…å®¹
                if not region_id:
                    logger.info("â„¹ æ— åŒºåŸŸIDï¼Œè·³è¿‡åŒºåŸŸç­›é€‰")
                if not os_name:
                    logger.info("â„¹ æ— OSåç§°ï¼Œè·³è¿‡åŒºåŸŸç­›é€‰")
                return str(base_content)
            
        except Exception as e:
            logger.info(f"âš  å†…å®¹æŸ¥æ‰¾å¤±è´¥: {e}")
            return ""

    def _get_product_key(self) -> str:
        """è·å–äº§å“é”®"""
        if hasattr(self, 'product_config') and 'product_key' in self.product_config:
            return self.product_config['product_key']
        
        # ä»æ–‡ä»¶è·¯å¾„æ¨æ–­
        if self.html_file_path:
            file_name = Path(self.html_file_path).stem
            if file_name.endswith('-index'):
                return file_name[:-6]
        
        return "unknown"