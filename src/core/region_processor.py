#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒºåŸŸå¤„ç†å™¨
ä»BaseCMSExtractorä¸­æå–çš„åŒºåŸŸå¤„ç†é€»è¾‘ï¼Œå»é™¤å¤æ‚çš„ç»§æ‰¿å…³ç³»
"""

import json
import os
from pathlib import Path
from typing import Dict, List, Any, Optional, Set
from bs4 import BeautifulSoup, Tag


class RegionProcessor:
    """åŒºåŸŸå¤„ç†é€»è¾‘ï¼Œä»BaseCMSExtractorä¸­æå–"""

    def __init__(self, config_file: str = "data/configs/soft-category.json"):
        self.config_file = config_file
        self.region_config = self._load_region_config()
        print(f"âœ“ åŒºåŸŸå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ åŒºåŸŸé…ç½®æ–‡ä»¶: {config_file}")

    def _load_region_config(self) -> Dict[str, Any]:
        """åŠ è½½åŒºåŸŸé…ç½®æ–‡ä»¶"""
        if os.path.exists(self.config_file):
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    raw_config = json.load(f)

                # å¦‚æœé…ç½®æ˜¯æ•°ç»„æ ¼å¼ï¼Œè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                if isinstance(raw_config, list):
                    config = self._convert_array_config_to_dict(raw_config)
                    print(f"ğŸ“‹ åŠ è½½åŒºåŸŸé…ç½®: {len(raw_config)} ä¸ªé…ç½®é¡¹ï¼Œè½¬æ¢ä¸º {len(config)} ä¸ªäº§å“")
                else:
                    config = raw_config
                    print(f"ğŸ“‹ åŠ è½½åŒºåŸŸé…ç½®: {len(config)} ä¸ªäº§å“")

                return config
            except Exception as e:
                print(f"âš  åŠ è½½åŒºåŸŸé…ç½®å¤±è´¥: {e}")
                return {}
        else:
            print(f"âš  åŒºåŸŸé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_file}")
            return {}

    def _convert_array_config_to_dict(self, array_config: List[Dict[str, Any]]) -> Dict[str, Any]:
        """å°†æ•°ç»„æ ¼å¼çš„é…ç½®è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        dict_config = {}

        for item in array_config:
            if not isinstance(item, dict):
                continue

            os_name = item.get('os', '')
            region = item.get('region', '')
            table_ids = item.get('tableIDs', [])

            if not os_name or not region:
                continue

            # æ ‡å‡†åŒ–äº§å“åç§°ï¼ˆè½¬æ¢ä¸ºæ–‡ä»¶åæ ¼å¼ï¼‰
            product_key = self._normalize_product_name(os_name)

            if product_key not in dict_config:
                dict_config[product_key] = {}

            dict_config[product_key][region] = table_ids

        return dict_config

    def _normalize_product_name(self, os_name: str) -> str:
        """æ ‡å‡†åŒ–äº§å“åç§°ä¸ºæ–‡ä»¶åæ ¼å¼"""
        # äº§å“åç§°æ˜ å°„è¡¨
        name_mapping = {
            'API Management': 'api-management-index',
            'Azure Database for MySQL': 'mysql-index',
            'Azure Cosmos DB': 'cosmos-db-index',
            'Storage Files': 'storage-files-index',
            'Data Factory SSIS': 'ssis-index',
            'Power BI Embedded': 'power-bi-embedded-index',
            'Cognitive Services': 'cognitive-services-index',
            'Anomaly Detector': 'anomaly-detector-index',
            'Machine Learning Server': 'machine-learning-server-index',
            'Azure_Data_Lake_Storage_Gen': 'storage_data-lake_index',
            'databricks': 'databricks-index'
        }

        return name_mapping.get(os_name, os_name.lower().replace(' ', '-'))

    def detect_available_regions(self, soup: BeautifulSoup) -> List[str]:
        """åŠ¨æ€æ£€æµ‹HTMLä¸­å®é™…å­˜åœ¨çš„åŒºåŸŸ"""
        print("ğŸ” æ£€æµ‹å¯ç”¨åŒºåŸŸ...")
        
        detected_regions = set()
        
        # æ–¹æ³•1: æ£€æŸ¥region-containerç±»
        region_containers = soup.find_all(class_='region-container')
        for container in region_containers:
            region_id = container.get('id')
            if region_id:
                detected_regions.add(region_id)
        
        # æ–¹æ³•2: æ£€æŸ¥data-regionå±æ€§
        region_elements = soup.find_all(attrs={'data-region': True})
        for element in region_elements:
            region_id = element.get('data-region')
            if region_id:
                detected_regions.add(region_id)
        
        # æ–¹æ³•3: æ£€æŸ¥å¸¸è§çš„åŒºåŸŸIDæ¨¡å¼
        common_region_patterns = [
            'china-north', 'china-east',
            'china-north2', 'china-east2',
            'china-north3', 'china-east3',
        ]
        
        for pattern in common_region_patterns:
            elements = soup.find_all(id=lambda x: x and pattern in x.lower())
            if elements:
                detected_regions.add(pattern)
        
        # æ–¹æ³•4: æ£€æŸ¥selecté€‰é¡¹ä¸­çš„åŒºåŸŸ
        region_selects = soup.find_all('select')
        for select in region_selects:
            select_id = select.get('id', '').lower()
            if 'region' in select_id or 'location' in select_id:
                options = select.find_all('option')
                for option in options:
                    value = option.get('value')
                    if value and len(value) > 2:  # è¿‡æ»¤ç©ºå€¼å’Œè¿‡çŸ­çš„å€¼
                        detected_regions.add(value)
        
        detected_list = sorted(list(detected_regions))
        print(f"  âœ“ æ£€æµ‹åˆ° {len(detected_list)} ä¸ªåŒºåŸŸ: {detected_list}")
        
        return detected_list

    def extract_region_contents(self, soup: BeautifulSoup, html_file_path: str) -> Dict[str, Any]:
        """æå–å„åŒºåŸŸçš„å†…å®¹"""
        print("ğŸŒ æå–åŒºåŸŸå†…å®¹...")
        
        region_contents = {}
        
        # è·å–æ–‡ä»¶åç”¨äºåŒºåŸŸé…ç½®æŸ¥è¯¢
        filename = Path(html_file_path).stem
        
        # æ£€æµ‹å¯ç”¨åŒºåŸŸ
        available_regions = self.detect_available_regions(soup)
        
        if not available_regions:
            print("  â„¹ æœªæ£€æµ‹åˆ°å…·ä½“åŒºåŸŸï¼Œä½¿ç”¨å…¨å±€å†…å®¹")
            region_contents['global'] = self._extract_global_content(soup)
            return region_contents
        
        # ä¸ºæ¯ä¸ªåŒºåŸŸæå–å†…å®¹
        for region_id in available_regions:
            print(f"  ğŸ“ å¤„ç†åŒºåŸŸ: {region_id}")
            
            try:
                # åº”ç”¨åŒºåŸŸç­›é€‰
                region_soup = self.apply_region_filtering(soup, region_id, filename)
                
                # æå–åŒºåŸŸç‰¹å®šå†…å®¹
                region_content = {
                    'region_id': region_id,
                    'pricing_tables': self._extract_region_pricing_tables(region_soup, region_id),
                    'feature_availability': self._extract_region_features(region_soup, region_id),
                    'region_notes': self._extract_region_notes(region_soup, region_id)
                }
                
                region_contents[region_id] = region_content
                
            except Exception as e:
                print(f"  âš  åŒºåŸŸ {region_id} å†…å®¹æå–å¤±è´¥: {e}")
                continue
        
        print(f"  âœ“ æˆåŠŸæå– {len(region_contents)} ä¸ªåŒºåŸŸçš„å†…å®¹")
        return region_contents

    def apply_region_filtering(self, soup: BeautifulSoup, region_id: str, 
                             filename: str = "") -> BeautifulSoup:
        """åº”ç”¨åŒºåŸŸç­›é€‰åˆ°soupå¯¹è±¡"""
        print(f"ğŸ”§ åº”ç”¨åŒºåŸŸç­›é€‰: {region_id}")
        
        # åˆ›å»ºsoupçš„å‰¯æœ¬
        filtered_soup = BeautifulSoup(str(soup), 'html.parser')
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¯¥äº§å“çš„åŒºåŸŸé…ç½®
        product_config = self.region_config.get(filename, {})
        
        if not product_config:
            print(f"  â„¹ äº§å“ {filename} æ— åŒºåŸŸé…ç½®ï¼Œä¿ç•™æ‰€æœ‰å†…å®¹")
            return filtered_soup
        
        region_tables = product_config.get(region_id, [])
        
        if not region_tables:
            print(f"  â„¹ åŒºåŸŸ {region_id} æ— ç‰¹å®šè¡¨æ ¼é…ç½®ï¼Œä¿ç•™æ‰€æœ‰è¡¨æ ¼")
            return filtered_soup
        
        # ç§»é™¤æŒ‡å®šçš„è¡¨æ ¼
        tables_removed = 0
        removed_table_ids = []

        for table_id in region_tables:
            # å¤„ç†å¸¦#å·å’Œä¸å¸¦#å·çš„table_id
            clean_table_id = table_id.replace('#', '') if table_id.startswith('#') else table_id

            # æŸ¥æ‰¾å…ƒç´ ï¼ˆå…ˆå°è¯•å¸¦#çš„IDï¼Œå†å°è¯•ä¸å¸¦#çš„ï¼‰
            elements = filtered_soup.find_all(id=clean_table_id)
            if not elements and not table_id.startswith('#'):
                # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•æŸ¥æ‰¾å¸¦#å‰ç¼€çš„
                elements = filtered_soup.find_all(id=f"#{table_id}")

            for element in elements:
                # ç§»é™¤è¡¨æ ¼åŠå…¶ç›¸å…³çš„å‰ç½®å†…å®¹
                self._remove_table_with_related_content(element, clean_table_id)
                tables_removed += 1
                removed_table_ids.append(table_id)

        if tables_removed > 0:
            print(f"  âœ“ ç§»é™¤äº† {tables_removed} ä¸ªåŒºåŸŸç‰¹å®šè¡¨æ ¼: {removed_table_ids}")

        # åœ¨filtered_soupä¸­æ·»åŠ ä¸€ä¸ªéšè—çš„å…ƒæ•°æ®æ ‡ç­¾ï¼Œè®°å½•è¢«ç§»é™¤çš„table IDs
        if removed_table_ids:
            metadata_comment = filtered_soup.new_string(f"<!-- Removed table IDs for region {region_id}: {', '.join(removed_table_ids)} -->")
            if filtered_soup.body:
                filtered_soup.body.insert(0, metadata_comment)

        return filtered_soup

    def _remove_table_with_related_content(self, table_element, table_id: str):
        """ç§»é™¤è¡¨æ ¼åŠå…¶ç›¸å…³çš„å‰ç½®å†…å®¹ï¼ˆæ ‡é¢˜ã€è¯´æ˜ç­‰ï¼‰"""

        print(f"    ğŸ—‘ï¸ ç§»é™¤è¡¨æ ¼åŠç›¸å…³å†…å®¹: {table_id}")

        # æ”¶é›†è¦ç§»é™¤çš„å…ƒç´ 
        elements_to_remove = [table_element]

        # å‘å‰æŸ¥æ‰¾ç›¸å…³çš„å‰ç½®å†…å®¹
        current = table_element.previous_sibling

        while current:
            if hasattr(current, 'name'):
                # å¦‚æœæ˜¯æ ‡ç­¾å…ƒç´ 
                if current.name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
                    # æ‰¾åˆ°æ ‡é¢˜ï¼Œæ·»åŠ åˆ°ç§»é™¤åˆ—è¡¨å¹¶åœæ­¢
                    elements_to_remove.append(current)
                    print(f"      ğŸ“‹ ç§»é™¤ç›¸å…³æ ‡é¢˜: {current.name} - {current.get_text(strip=True)[:50]}")
                    break
                elif current.name == 'p':
                    # è¯´æ˜æ–‡å­—ï¼Œæ·»åŠ åˆ°ç§»é™¤åˆ—è¡¨
                    elements_to_remove.append(current)
                    print(f"      ğŸ“ ç§»é™¤ç›¸å…³è¯´æ˜: {current.get_text(strip=True)[:50]}")
                elif current.name == 'div' and 'tags-date' in current.get('class', []):
                    # ä»·æ ¼è¯´æ˜divï¼Œæ·»åŠ åˆ°ç§»é™¤åˆ—è¡¨
                    elements_to_remove.append(current)
                    print(f"      ğŸ’° ç§»é™¤ä»·æ ¼è¯´æ˜: {current.get_text(strip=True)[:50]}")
                elif current.name == 'br':
                    # æ¢è¡Œç¬¦ï¼Œæ·»åŠ åˆ°ç§»é™¤åˆ—è¡¨
                    elements_to_remove.append(current)
                elif current.name in ['table', 'div'] and current.get('id'):
                    # é‡åˆ°å…¶ä»–æœ‰IDçš„é‡è¦å…ƒç´ ï¼Œåœæ­¢
                    break
            elif hasattr(current, 'string') and current.string and current.string.strip():
                # å¦‚æœæ˜¯æœ‰å†…å®¹çš„æ–‡æœ¬èŠ‚ç‚¹ï¼Œåœæ­¢
                break

            current = current.previous_sibling

        # ç§»é™¤æ‰€æœ‰æ”¶é›†åˆ°çš„å…ƒç´ 
        for element in elements_to_remove:
            try:
                element.decompose()
            except Exception as e:
                print(f"      âš  ç§»é™¤å…ƒç´ å¤±è´¥: {e}")

    def _extract_global_content(self, soup: BeautifulSoup) -> Dict[str, Any]:
        """æå–å…¨å±€å†…å®¹ï¼ˆæ— åŒºåŸŸåŒºåˆ†ï¼‰"""
        return {
            'type': 'global',
            'pricing_tables': self._extract_pricing_tables_simple(soup),
            'content_summary': self._get_content_summary(soup)
        }

    def _extract_region_pricing_tables(self, soup: BeautifulSoup, region_id: str) -> List[Dict[str, Any]]:
        """æå–åŒºåŸŸç‰¹å®šçš„å®šä»·è¡¨æ ¼"""
        pricing_tables = []
        
        # æŸ¥æ‰¾å®šä»·ç›¸å…³çš„è¡¨æ ¼
        tables = soup.find_all('table')
        
        for i, table in enumerate(tables):
            table_text = table.get_text(strip=True)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºå®šä»·è¡¨æ ¼
            if self._is_pricing_table(table_text):
                table_info = {
                    'table_id': f"table_{region_id}_{i}",
                    'region': region_id,
                    'content': table_text[:1000],  # é™åˆ¶å†…å®¹é•¿åº¦
                    'row_count': len(table.find_all('tr')),
                    'has_pricing': any(keyword in table_text.lower() 
                                     for keyword in ['ï¿¥', '$', 'ä»·æ ¼', 'price', 'è´¹ç”¨'])
                }
                
                pricing_tables.append(table_info)
        
        return pricing_tables

    def _extract_region_features(self, soup: BeautifulSoup, region_id: str) -> List[str]:
        """æå–åŒºåŸŸç‰¹å®šçš„åŠŸèƒ½å¯ç”¨æ€§"""
        features = []
        
        # æŸ¥æ‰¾åŠŸèƒ½åˆ—è¡¨
        feature_lists = soup.find_all(['ul', 'ol'])
        
        for ul in feature_lists:
            # æ£€æŸ¥æ˜¯å¦ä¸ºåŠŸèƒ½åˆ—è¡¨
            ul_text = ul.get_text(strip=True).lower()
            if any(keyword in ul_text for keyword in ['åŠŸèƒ½', 'feature', 'ç‰¹æ€§', 'æ”¯æŒ']):
                items = ul.find_all('li')
                for item in items[:10]:  # é™åˆ¶æ•°é‡
                    item_text = item.get_text(strip=True)
                    if len(item_text) > 5:  # è¿‡æ»¤è¿‡çŸ­çš„å†…å®¹
                        features.append(item_text)
        
        return features

    def _extract_region_notes(self, soup: BeautifulSoup, region_id: str) -> List[str]:
        """æå–åŒºåŸŸç‰¹å®šçš„è¯´æ˜ä¿¡æ¯"""
        notes = []
        
        # æŸ¥æ‰¾åŒ…å«åŒºåŸŸä¿¡æ¯çš„æ®µè½
        paragraphs = soup.find_all('p')
        
        for p in paragraphs:
            p_text = p.get_text(strip=True)
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«åŒºåŸŸç›¸å…³ä¿¡æ¯
            if any(keyword in p_text.lower() for keyword in 
                  ['åŒºåŸŸ', 'region', 'åœ°åŒº', 'å¯ç”¨æ€§', 'availability']):
                if len(p_text) > 20:  # è¿‡æ»¤è¿‡çŸ­çš„å†…å®¹
                    notes.append(p_text[:200])  # é™åˆ¶é•¿åº¦
        
        return notes

    def _is_pricing_table(self, table_text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå®šä»·è¡¨æ ¼"""
        pricing_keywords = [
            'ä»·æ ¼', 'price', 'å®šä»·', 'pricing', 'è´¹ç”¨', 'cost', 
            'ï¿¥', '$', 'å…ƒ', 'ç¾å…ƒ', 'usd', 'rmb', 'cny'
        ]
        
        text_lower = table_text.lower()
        return any(keyword in text_lower for keyword in pricing_keywords)

    def _extract_pricing_tables_simple(self, soup: BeautifulSoup) -> List[Dict[str, Any]]:
        """ç®€å•çš„å®šä»·è¡¨æ ¼æå–"""
        pricing_tables = []
        tables = soup.find_all('table')
        
        for i, table in enumerate(tables):
            table_text = table.get_text(strip=True)
            
            if self._is_pricing_table(table_text):
                pricing_tables.append({
                    'table_id': f"global_table_{i}",
                    'content': table_text[:500],  # é™åˆ¶å†…å®¹é•¿åº¦
                    'row_count': len(table.find_all('tr'))
                })
        
        return pricing_tables

    def _get_content_summary(self, soup: BeautifulSoup) -> Dict[str, Any]:
        """è·å–å†…å®¹æ‘˜è¦"""
        return {
            'total_tables': len(soup.find_all('table')),
            'total_lists': len(soup.find_all(['ul', 'ol'])),
            'total_headings': len(soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])),
            'has_forms': len(soup.find_all('form')) > 0,
            'has_scripts': len(soup.find_all('script')) > 0
        }

    def get_region_mapping(self) -> Dict[str, str]:
        """è·å–åŒºåŸŸæ˜ å°„å…³ç³»"""
        # æ ‡å‡†çš„Azure ChinaåŒºåŸŸæ˜ å°„
        return {
            'china-north': 'ä¸­å›½åŒ—éƒ¨',
            'china-east': 'ä¸­å›½ä¸œéƒ¨', 
            'china-south': 'ä¸­å›½å—éƒ¨',
            'china-north-2': 'ä¸­å›½åŒ—éƒ¨2',
            'china-east-2': 'ä¸­å›½ä¸œéƒ¨2',
            'beijing': 'åŒ—äº¬',
            'shanghai': 'ä¸Šæµ·',
            'guangzhou': 'å¹¿å·',
            'shenzhen': 'æ·±åœ³'
        }

    def normalize_region_id(self, region_id: str) -> str:
        """æ ‡å‡†åŒ–åŒºåŸŸID"""
        # è½¬æ¢ä¸ºå°å†™å¹¶æ›¿æ¢å¸¸è§å˜ä½“
        normalized = region_id.lower().strip()
        
        # å¤„ç†å¸¸è§çš„åŒºåŸŸåç§°å˜ä½“
        region_variants = {
            'cn-north': 'china-north',
            'cn-east': 'china-east', 
            'cn-south': 'china-south',
            'åŒ—äº¬': 'beijing',
            'ä¸Šæµ·': 'shanghai',
            'å¹¿å·': 'guangzhou',
            'æ·±åœ³': 'shenzhen'
        }
        
        return region_variants.get(normalized, normalized)

    def validate_region_config(self) -> Dict[str, Any]:
        """éªŒè¯åŒºåŸŸé…ç½®çš„å®Œæ•´æ€§"""
        validation_result = {
            'is_valid': True,
            'total_products': len(self.region_config),
            'total_regions': set(),
            'issues': []
        }
        
        for product, regions in self.region_config.items():
            if not isinstance(regions, dict):
                validation_result['issues'].append(f"äº§å“ {product} çš„é…ç½®ä¸æ˜¯å­—å…¸æ ¼å¼")
                validation_result['is_valid'] = False
                continue
                
            for region_id, table_ids in regions.items():
                validation_result['total_regions'].add(region_id)
                
                if not isinstance(table_ids, list):
                    validation_result['issues'].append(
                        f"äº§å“ {product} åŒºåŸŸ {region_id} çš„è¡¨æ ¼IDä¸æ˜¯åˆ—è¡¨æ ¼å¼"
                    )
                    validation_result['is_valid'] = False
        
        validation_result['total_regions'] = len(validation_result['total_regions'])
        
        return validation_result

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–åŒºåŸŸå¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'total_products_configured': len(self.region_config),
            'regions_by_product': {},
            'most_common_regions': {},
            'total_table_exclusions': 0
        }
        
        all_regions = []
        
        # æ£€æŸ¥region_configæ˜¯å¦ä¸ºå­—å…¸æ ¼å¼
        if not isinstance(self.region_config, dict):
            return stats
            
        for product, regions in self.region_config.items():
            if isinstance(regions, dict):
                product_regions = list(regions.keys())
                stats['regions_by_product'][product] = len(product_regions)
                all_regions.extend(product_regions)
                
                # ç»Ÿè®¡è¡¨æ ¼æ’é™¤æ•°é‡
                for table_list in regions.values():
                    if isinstance(table_list, list):
                        stats['total_table_exclusions'] += len(table_list)
            else:
                # å¦‚æœregionsä¸æ˜¯å­—å…¸ï¼Œè·³è¿‡
                stats['regions_by_product'][product] = 0
        
        # ç»Ÿè®¡æœ€å¸¸è§çš„åŒºåŸŸ
        from collections import Counter
        region_counts = Counter(all_regions)
        stats['most_common_regions'] = dict(region_counts.most_common(10))
        
        return stats